{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dcd155e-23ad-4a5d-92b8-db0db422b67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 경고(W) 메시지만 숨김"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65d8b071-1b93-4d19-b8ec-3d0549e87d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf14af21-206c-4d92-9019-734e5917162f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 메모리 동적 할당 활성화 완료\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# GPU 환경이 아닌 CoreML에서는 이 설정이 필요 없음\n",
    "# 따라서 변환 시 주석 처리하거나 삭제 가능\n",
    "# 단, 로컬 학습 시에는 유지 가능하므로 조건 분기 처리\n",
    "import platform\n",
    "if platform.system() != 'Darwin':\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(\"GPU 메모리 동적 할당 활성화 완료\")\n",
    "        except RuntimeError as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4bb29387-ac0b-45ac-9625-1dfe66e618ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 데이터 크기: (39999, 3)\n",
      "Test 데이터 크기: (4999, 3)\n",
      "Validation 데이터 크기: (4999, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>39087</th>\n",
       "      <th>내가 톰행크스를 좋아하긴 했나보다... 초기 영화 빼고는 다 봤네.</th>\n",
       "      <th>2,13,15,16,29,39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30893</td>\n",
       "      <td>정말 상상을 초월하는 무개념 진상들 상대하다 우울증, 공항장애 걸리는 공무원 많아요...</td>\n",
       "      <td>0,5,7,10,19,22,29,35,36,38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45278</td>\n",
       "      <td>새로운 세상과 조우한 자의 어린아이 같은 반응, 어쩌면 회복된 것은 눈이 아닌 순수...</td>\n",
       "      <td>1,2,7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16398</td>\n",
       "      <td>미역은 원생생물계 산호초는 동물ㅇㅇ 아 미역이 바다의 새ㄱㅇㄱㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ</td>\n",
       "      <td>9,15,20,23,26,28,29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13653</td>\n",
       "      <td>네 맞습니다 플스는 역시 30프레임이 어울리죠 ㅎ</td>\n",
       "      <td>1,2,8,9,11,13,15,16,28,29,32,40,42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13748</td>\n",
       "      <td>어릴 때 했던 건데 아직도 볼 때마다 뒤통수 얼얼함 ㅋㅋㅋㅋ</td>\n",
       "      <td>2,15,23,24,25,28,33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   39087              내가 톰행크스를 좋아하긴 했나보다... 초기 영화 빼고는 다 봤네.  \\\n",
       "0  30893  정말 상상을 초월하는 무개념 진상들 상대하다 우울증, 공항장애 걸리는 공무원 많아요...   \n",
       "1  45278  새로운 세상과 조우한 자의 어린아이 같은 반응, 어쩌면 회복된 것은 눈이 아닌 순수...   \n",
       "2  16398       미역은 원생생물계 산호초는 동물ㅇㅇ 아 미역이 바다의 새ㄱㅇㄱㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ   \n",
       "3  13653                        네 맞습니다 플스는 역시 30프레임이 어울리죠 ㅎ   \n",
       "4  13748                  어릴 때 했던 건데 아직도 볼 때마다 뒤통수 얼얼함 ㅋㅋㅋㅋ   \n",
       "\n",
       "                     2,13,15,16,29,39  \n",
       "0          0,5,7,10,19,22,29,35,36,38  \n",
       "1                               1,2,7  \n",
       "2                 9,15,20,23,26,28,29  \n",
       "3  1,2,8,9,11,13,15,16,28,29,32,40,42  \n",
       "4                 2,15,23,24,25,28,33  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# KOTE 데이터셋 로드\n",
    "train_df = pd.read_csv(\"KOTE/train.tsv\", sep='\\t')\n",
    "test_df = pd.read_csv(\"KOTE/test.tsv\", sep='\\t')\n",
    "val_df = pd.read_csv(\"KOTE/val.tsv\", sep='\\t')\n",
    "\n",
    "# 데이터 확인\n",
    "print(f\"Train 데이터 크기: {train_df.shape}\")\n",
    "print(f\"Test 데이터 크기: {test_df.shape}\")\n",
    "print(f\"Validation 데이터 크기: {val_df.shape}\")\n",
    "\n",
    "# 데이터 샘플 출력\n",
    "#train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ca065fe-7fbd-48c4-88c1-7df08a0ee135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id                                           comments  \\\n",
      "0  39087              내가 톰행크스를 좋아하긴 했나보다... 초기 영화 빼고는 다 봤네.   \n",
      "1  30893  정말 상상을 초월하는 무개념 진상들 상대하다 우울증, 공항장애 걸리는 공무원 많아요...   \n",
      "2  45278  새로운 세상과 조우한 자의 어린아이 같은 반응, 어쩌면 회복된 것은 눈이 아닌 순수...   \n",
      "3  16398       미역은 원생생물계 산호초는 동물ㅇㅇ 아 미역이 바다의 새ㄱㅇㄱㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ   \n",
      "4  13653                        네 맞습니다 플스는 역시 30프레임이 어울리죠 ㅎ   \n",
      "\n",
      "                               labels  \n",
      "0                    2,13,15,16,29,39  \n",
      "1          0,5,7,10,19,22,29,35,36,38  \n",
      "2                               1,2,7  \n",
      "3                 9,15,20,23,26,28,29  \n",
      "4  1,2,8,9,11,13,15,16,28,29,32,40,42  \n",
      "📌 데이터 컬럼 목록: Index(['id', 'comments', 'labels'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ✅ CoreML 변환과 직접 관련은 없지만, 변환 대상 모델 학습에 필요한 데이터 전처리 단계이므로 유지\n",
    "train_df = pd.read_csv(\"KOTE/train.tsv\", sep='\\t', names=['id', 'comments', 'labels'], header=None)\n",
    "test_df = pd.read_csv(\"KOTE/test.tsv\", sep='\\t', names=['id', 'comments', 'labels'], header=None)\n",
    "val_df = pd.read_csv(\"KOTE/val.tsv\", sep='\\t', names=['id', 'comments', 'labels'], header=None)\n",
    "\n",
    "# ✅ 변환 후에는 출력이 필요 없으므로 주석 처리하거나 삭제\n",
    "# print(train_df.head())\n",
    "# print(\"📌 데이터 컬럼 목록:\", train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2bcd9a8e-b270-4309-90bb-d36224269719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>내가 톰행크스를 좋아하긴 했나보다... 초기 영화 빼고는 다 봤네.</td>\n",
       "      <td>내가 톰행크스를 좋아하긴 했나보다 초기 영화 빼고는 다 봤네</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>정말 상상을 초월하는 무개념 진상들 상대하다 우울증, 공항장애 걸리는 공무원 많아요...</td>\n",
       "      <td>정말 상상을 초월하는 무개념 진상들 상대하다 우울증 공항장애 걸리는 공무원 많아요 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>새로운 세상과 조우한 자의 어린아이 같은 반응, 어쩌면 회복된 것은 눈이 아닌 순수...</td>\n",
       "      <td>새로운 세상과 조우한 자의 어린아이 같은 반응 어쩌면 회복된 것은 눈이 아닌 순수함...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>미역은 원생생물계 산호초는 동물ㅇㅇ 아 미역이 바다의 새ㄱㅇㄱㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ</td>\n",
       "      <td>미역은 원생생물계 산호초는 동물ㅇㅇ 아 미역이 바다의 새ㄱㅇㄱㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>네 맞습니다 플스는 역시 30프레임이 어울리죠 ㅎ</td>\n",
       "      <td>네 맞습니다 플스는 역시 30프레임이 어울리죠 ㅎ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>어릴 때 했던 건데 아직도 볼 때마다 뒤통수 얼얼함 ㅋㅋㅋㅋ</td>\n",
       "      <td>어릴 때 했던 건데 아직도 볼 때마다 뒤통수 얼얼함 ㅋㅋㅋㅋ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>물갈이약 구매했어요...미미네에서 수조2개랑 여러가지 용품사면서 3~4번 주문했었는...</td>\n",
       "      <td>물갈이약 구매했어요미미네에서 수조2개랑 여러가지 용품사면서 34번 주문했었는데 그 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>십일조는 겨우60인데? 나머지 다 어디감? 혹시 엄마아빠 그랜져따로타고, 외식자주하...</td>\n",
       "      <td>십일조는 겨우60인데 나머지 다 어디감 혹시 엄마아빠 그랜져따로타고 외식자주하는거아...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>90년 줘야 하는거 아닌가?  쓰레기같은 것들.</td>\n",
       "      <td>90년 줘야 하는거 아닌가 쓰레기같은 것들</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>아주 부착성도 좋고 효과 100점 입니다</td>\n",
       "      <td>아주 부착성도 좋고 효과 100점 입니다</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments  \\\n",
       "0              내가 톰행크스를 좋아하긴 했나보다... 초기 영화 빼고는 다 봤네.   \n",
       "1  정말 상상을 초월하는 무개념 진상들 상대하다 우울증, 공항장애 걸리는 공무원 많아요...   \n",
       "2  새로운 세상과 조우한 자의 어린아이 같은 반응, 어쩌면 회복된 것은 눈이 아닌 순수...   \n",
       "3       미역은 원생생물계 산호초는 동물ㅇㅇ 아 미역이 바다의 새ㄱㅇㄱㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ   \n",
       "4                        네 맞습니다 플스는 역시 30프레임이 어울리죠 ㅎ   \n",
       "5                  어릴 때 했던 건데 아직도 볼 때마다 뒤통수 얼얼함 ㅋㅋㅋㅋ   \n",
       "6  물갈이약 구매했어요...미미네에서 수조2개랑 여러가지 용품사면서 3~4번 주문했었는...   \n",
       "7  십일조는 겨우60인데? 나머지 다 어디감? 혹시 엄마아빠 그랜져따로타고, 외식자주하...   \n",
       "8                         90년 줘야 하는거 아닌가?  쓰레기같은 것들.   \n",
       "9                             아주 부착성도 좋고 효과 100점 입니다   \n",
       "\n",
       "                                          clean_text  \n",
       "0                  내가 톰행크스를 좋아하긴 했나보다 초기 영화 빼고는 다 봤네  \n",
       "1  정말 상상을 초월하는 무개념 진상들 상대하다 우울증 공항장애 걸리는 공무원 많아요 ...  \n",
       "2  새로운 세상과 조우한 자의 어린아이 같은 반응 어쩌면 회복된 것은 눈이 아닌 순수함...  \n",
       "3       미역은 원생생물계 산호초는 동물ㅇㅇ 아 미역이 바다의 새ㄱㅇㄱㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ  \n",
       "4                        네 맞습니다 플스는 역시 30프레임이 어울리죠 ㅎ  \n",
       "5                  어릴 때 했던 건데 아직도 볼 때마다 뒤통수 얼얼함 ㅋㅋㅋㅋ  \n",
       "6  물갈이약 구매했어요미미네에서 수조2개랑 여러가지 용품사면서 34번 주문했었는데 그 ...  \n",
       "7  십일조는 겨우60인데 나머지 다 어디감 혹시 엄마아빠 그랜져따로타고 외식자주하는거아...  \n",
       "8                            90년 줘야 하는거 아닌가 쓰레기같은 것들  \n",
       "9                             아주 부착성도 좋고 효과 100점 입니다  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# 텍스트 정제 함수 (숫자 유지)\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"[^가-힣ㄱ-ㅎㅏ-ㅣ0-9\\s]\", \"\", text)  # 한글, 숫자, 공백 제외한 문자 제거\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # 연속된 공백 제거\n",
    "    return text\n",
    "\n",
    "# ✅ CoreML에서는 텍스트 전처리가 불가능하므로, 사전 정제는 필수\n",
    "train_df['clean_text'] = train_df['comments'].apply(clean_text)\n",
    "test_df['clean_text'] = test_df['comments'].apply(clean_text)\n",
    "val_df['clean_text'] = val_df['comments'].apply(clean_text)\n",
    "\n",
    "# ✅ 출력은 학습용 확인용 → 변환 후에는 주석 처리\n",
    "# train_df[['comments', 'clean_text']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4802127f-31d4-4891-a172-6a8077ae44a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 텍스트 데이터셋 로드\n",
    "train_texts = train_df['clean_text'].tolist()\n",
    "test_texts = test_df['clean_text'].tolist()\n",
    "val_texts = val_df['clean_text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9636f8af-0a69-4d81-b617-e07ec6c6376a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels\n",
      "0,6,10,22,23,33                       125\n",
      "0,6,10,12,22,23,33                    108\n",
      "24                                     83\n",
      "2,28,40,42                             65\n",
      "0,10,22,37                             55\n",
      "                                     ... \n",
      "0,3,10,12,20,21,22,23,24,27,31,35       1\n",
      "0,5,10,19,20,22,25,27,31,36,38          1\n",
      "0,2,3,8,20,22,23,24,28,29,32,33,39      1\n",
      "1,11,14,15,16,27,29,38,39,41            1\n",
      "2,9,10,15,18,23,33,35,39                1\n",
      "Name: count, Length: 29332, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 감정 라벨 개수 확인\n",
    "#print(train_df['labels'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b09a5a33-5f28-49ea-b351-505875ab6217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fer2013_emotion_grouped\n",
      "0    16762\n",
      "6     8879\n",
      "3     6499\n",
      "4     4150\n",
      "5     2588\n",
      "2      776\n",
      "1      346\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# 감정을 7개 그룹으로 정리하는 매핑\n",
    "emotion_mapping = {\n",
    "    '기쁨': [42, 40, 28],\n",
    "    '슬픔': [5, 19, 25, 36],\n",
    "    '놀람': [39, 34, 15, 2],\n",
    "    '분노': [6, 22, 0],\n",
    "    '공포': [18, 41],\n",
    "    '혐오': [31, 21],\n",
    "    '중립': [24, 14, 43]\n",
    "}\n",
    "\n",
    "# FER2013 감정 인덱스 맵핑\n",
    "fer2013_label_mapping = {\n",
    "    '기쁨': 3, '슬픔': 5, '놀람': 6,\n",
    "    '분노': 0, '공포': 2, '혐오': 1, '중립': 4\n",
    "}\n",
    "\n",
    "def map_to_fer2013(label_str):\n",
    "    if pd.isna(label_str) or label_str == '':\n",
    "        return 4\n",
    "    label_list = list(map(int, label_str.split(',')))\n",
    "    matched_fer_labels = []\n",
    "    for num in label_list:\n",
    "        for kotem, kote_ids in emotion_mapping.items():\n",
    "            if num in kote_ids:\n",
    "                matched_fer_labels.append(fer2013_label_mapping[kotem])\n",
    "    if not matched_fer_labels:\n",
    "        return 4\n",
    "    return Counter(matched_fer_labels).most_common(1)[0][0]\n",
    "\n",
    "# 레이블 변환 적용\n",
    "train_df['fer2013_emotion_grouped'] = train_df['labels'].fillna('').apply(map_to_fer2013)\n",
    "test_df['fer2013_emotion_grouped'] = test_df['labels'].fillna('').apply(map_to_fer2013)\n",
    "val_df['fer2013_emotion_grouped'] = val_df['labels'].fillna('').apply(map_to_fer2013)\n",
    "\n",
    "# ✅ 출력은 학습 중 디버깅용 → CoreML 변환 시에는 주석 처리\n",
    "# print(train_df['fer2013_emotion_grouped'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71602852-08d6-4151-b5fb-737474394753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨 변환 결과: [6 5 6 6 3]\n"
     ]
    }
   ],
   "source": [
    "# ✅ 감정 라벨 (FER2013 매핑된 라벨)\n",
    "train_labels = train_df['fer2013_emotion_grouped'].values\n",
    "test_labels = test_df['fer2013_emotion_grouped'].values\n",
    "val_labels = val_df['fer2013_emotion_grouped'].values\n",
    "\n",
    "# ✅ 출력은 학습 중 확인용 → 변환 후에는 제거\n",
    "# print(\"라벨 변환 결과:\", train_labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ac71585-3e23-44f7-8b9b-d53900177378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename:\t/opt/homebrew/lib/mecab/dic/mecab-ko-dic/sys.dic\n",
      "version:\t102\n",
      "charset:\tUTF-8\n",
      "type:\t0\n",
      "size:\t816283\n",
      "left size:\t3822\n",
      "right size:\t2693\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ✅ mecab 사전 정보 출력은 개발 확인용으로만 사용\n",
    "# CoreML 환경 (iOS/macOS 추론 엔진)에서는 사용되지 않음\n",
    "# !mecab -D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6af99fc0-b1e4-4c4b-920e-c4e7d0eb2523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ MECAB 환경 설정 (로컬 학습 시에는 필요하나, CoreML 변환 후에는 불필요)\n",
    "# CoreML에는 토크나이저 포함 불가하므로 입력 시퀀스는 사전에 변환되어야 함\n",
    "import os\n",
    "os.environ[\"MECABRC\"] = \"/opt/homebrew/etc/mecabrc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a43a3a42-f0d9-477e-be4e-9f067d55140f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['이', '문장', '은', '형태소', '분석', '을', '테스트', '하', '는', '문장', '입니다', '.']\n"
     ]
    }
   ],
   "source": [
    "# ✅ mecab 형태소 분석기는 CoreML 환경에서는 사용 불가\n",
    "# 학습 시에는 사용 가능 → 변환된 입력 시퀀스를 .npy로 저장하여 모델에 공급해야 함\n",
    "\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "# 로컬 학습용 mecab 초기화\n",
    "mecab = Mecab(dicpath='/opt/homebrew/lib/mecab/dic/mecab-ko-dic')\n",
    "\n",
    "# ✅ 테스트 출력은 CoreML 변환 이후에는 제거\n",
    "# print(mecab.morphs(\"이 문장은 형태소 분석을 테스트하는 문장입니다.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "14e54bf0-28ba-41ae-a051-4c347d0fa577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          clean_text  \\\n",
      "0                  내가 톰행크스를 좋아하긴 했나보다 초기 영화 빼고는 다 봤네   \n",
      "1  정말 상상을 초월하는 무개념 진상들 상대하다 우울증 공항장애 걸리는 공무원 많아요 ...   \n",
      "2  새로운 세상과 조우한 자의 어린아이 같은 반응 어쩌면 회복된 것은 눈이 아닌 순수함...   \n",
      "3       미역은 원생생물계 산호초는 동물ㅇㅇ 아 미역이 바다의 새ㄱㅇㄱㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ   \n",
      "4                        네 맞습니다 플스는 역시 30프레임이 어울리죠 ㅎ   \n",
      "\n",
      "                                           tokenized  \n",
      "0  [내, 가, 톰행크스, 를, 좋아하, 긴, 했, 나, 보다, 초기, 영화, 빼, 고...  \n",
      "1  [정말, 상상, 을, 초월, 하, 는, 무, 개념, 진상, 들, 상대, 하, 다, ...  \n",
      "2  [새로운, 세상, 과, 조우, 한, 자, 의, 어린아이, 같, 은, 반응, 어쩌면,...  \n",
      "3  [미역, 은, 원생생물, 계, 산호초, 는, 동물, ㅇㅇ, 아, 미역, 이, 바다,...  \n",
      "4    [네, 맞, 습니다, 플, 스, 는, 역시, 30, 프레임, 이, 어울리, 죠, ㅎ]  \n"
     ]
    }
   ],
   "source": [
    "# ✅ CoreML에는 Mecab 등 형태소 분석기를 포함할 수 없으므로\n",
    "# 학습 시에만 형태소 단위 토큰화를 진행하고,\n",
    "# 변환 시에는 숫자 시퀀스로 저장된 결과만 사용해야 함.\n",
    "\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "# 로컬 학습용 mecab 경로 설정\n",
    "mecab = Mecab(dicpath='/opt/homebrew/Cellar/mecab-ko-dic/2.1.1-20180720/lib/mecab/dic/mecab-ko-dic')\n",
    "\n",
    "def tokenize(text):\n",
    "    return mecab.morphs(text)\n",
    "\n",
    "train_df['tokenized'] = train_df['clean_text'].apply(tokenize)\n",
    "test_df['tokenized'] = test_df['clean_text'].apply(tokenize)\n",
    "val_df['tokenized'] = val_df['clean_text'].apply(tokenize)\n",
    "\n",
    "# ✅ 변환 후 사용하지 않으므로 출력 제거\n",
    "# print(train_df[['clean_text', 'tokenized']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c8e5e24-2f21-48b8-b7f9-c473ccbce250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          clean_text  \\\n",
      "0                  내가 톰행크스를 좋아하긴 했나보다 초기 영화 빼고는 다 봤네   \n",
      "1  정말 상상을 초월하는 무개념 진상들 상대하다 우울증 공항장애 걸리는 공무원 많아요 ...   \n",
      "2  새로운 세상과 조우한 자의 어린아이 같은 반응 어쩌면 회복된 것은 눈이 아닌 순수함...   \n",
      "3       미역은 원생생물계 산호초는 동물ㅇㅇ 아 미역이 바다의 새ㄱㅇㄱㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ   \n",
      "4                        네 맞습니다 플스는 역시 30프레임이 어울리죠 ㅎ   \n",
      "\n",
      "                                           tokenized  \n",
      "0  [내, 톰행크스, 좋아하, 긴, 했, 나, 보다, 초기, 영화, 빼, 고, 다, 봤...  \n",
      "1  [정말, 상상, 을, 초월, 하, 무, 개념, 진상, 상대, 하, 다, 우울증, 공...  \n",
      "2  [새로운, 세상, 조우, 어린아이, 같, 반응, 어쩌면, 회복, 된, 것, 눈, 아...  \n",
      "3  [미역, 원생생물, 계, 산호초, 동물, ㅇㅇ, 아, 미역, 바다, 새, ㄱ, ㅇㄱ...  \n",
      "4          [네, 맞, 습니다, 플, 스, 역시, 30, 프레임, 어울리, 죠, ㅎ]  \n"
     ]
    }
   ],
   "source": [
    "# ✅ 불용어 제거는 CoreML 환경에서 불가능하므로 사전 처리 필수\n",
    "stopwords = [\n",
    "    \"의\", \"가\", \"이\", \"은\", \"들\", \"는\", \"걍\", \"과\",\n",
    "    \"를\", \"으로\", \"자\", \"에\", \"와\", \"한\", \"하다\", \"에서\",\n",
    "    \"요\", \"무엇\", \"어디\", \"하면\", \"이다\"\n",
    "]\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    return [token for token in tokens if token not in stopwords]\n",
    "\n",
    "# CoreML 모델 입력용 시퀀스 생성을 위해 불용어 제거 적용\n",
    "train_df['tokenized'] = train_df['tokenized'].apply(remove_stopwords)\n",
    "test_df['tokenized'] = test_df['tokenized'].apply(remove_stopwords)\n",
    "val_df['tokenized'] = val_df['tokenized'].apply(remove_stopwords)\n",
    "\n",
    "# ✅ 출력은 변환 후 필요 없음\n",
    "# print(train_df[['clean_text', 'tokenized']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "39ed77d9-f1f2-4ae4-bfce-0096be37b4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "패딩 후 데이터 크기: (40000, 188)\n",
      "✅ 텍스트 데이터셋 준비 완료!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# ✅ 전처리된 토큰들을 공백으로 연결\n",
    "train_texts = train_df['tokenized'].apply(lambda x: ' '.join(x)).tolist()\n",
    "test_texts = test_df['tokenized'].apply(lambda x: ' '.join(x)).tolist()\n",
    "val_texts = val_df['tokenized'].apply(lambda x: ' '.join(x)).tolist()\n",
    "\n",
    "# ✅ 토크나이저 정의 및 커스텀 토큰 추가\n",
    "tokenizer = Tokenizer(oov_token=\"<OOV>\", filters='')\n",
    "custom_tokens = [\n",
    "    \"ㅋㅋㅋ\", \"ㅎㅎㅎ\", \"ㅠㅠ\", \"ㅜㅜ\", \"ㅡㅡ\", \"헐\", \"헉\", \"ㄷㄷ\", \"대박\",\n",
    "    \"ㄹㅇ\", \"ㄴㄴ\", \"ㅇㅇ\", \"ㅇㅋ\", \"ㄱㄱ\", \"ㄱㅅ\", \"ㅊㅋ\", \"ㅅㄱ\", \"ㅎㅇ\", \"ㅂㅇ\", \"ㅇㅈ\",\n",
    "    \"노잼\", \"꿀잼\", \"갑분싸\", \"잼민이\", \"현웃\", \"만렙\", \"어그로\", \"불금\", \"ㄹㅈㄷ\", \"쩐다\", \"존맛\", \"솔까\", \"극혐\",\n",
    "    \"ㅅㅂ\", \"ㅈㄹ\", \"ㅄ\", \"존나\"\n",
    "]\n",
    "tokenizer.fit_on_texts(train_texts + [\" \".join(custom_tokens)])\n",
    "\n",
    "# ✅ 단어 집합 크기\n",
    "MAX_VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
    "\n",
    "# ✅ 시퀀스로 변환\n",
    "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
    "val_sequences = tokenizer.texts_to_sequences(val_texts)\n",
    "\n",
    "# ✅ 최대 시퀀스 길이 결정 및 패딩\n",
    "MAX_SEQUENCE_LENGTH = max(len(seq) for seq in train_sequences)\n",
    "train_padded = pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "test_padded = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "val_padded = pad_sequences(val_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "\n",
    "# ✅ TensorFlow Dataset 구성\n",
    "BATCH_SIZE = 64\n",
    "train_text_ds = tf.data.Dataset.from_tensor_slices((train_padded, train_labels)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_text_ds = tf.data.Dataset.from_tensor_slices((test_padded, test_labels)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "val_text_ds = tf.data.Dataset.from_tensor_slices((val_padded, val_labels)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# ✅ CoreML 입력에 사용되기 위해 시퀀스와 라벨 저장\n",
    "np.save(\"train_texts.npy\", train_padded)\n",
    "np.save(\"test_texts.npy\", test_padded)\n",
    "np.save(\"val_texts.npy\", val_padded)\n",
    "\n",
    "np.save(\"train_labels.npy\", train_labels)\n",
    "np.save(\"test_labels.npy\", test_labels)\n",
    "np.save(\"val_labels.npy\", val_labels)\n",
    "\n",
    "# ✅ Tokenizer 저장 (CoreML 입력 처리용)\n",
    "with open(\"tokenizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "\n",
    "# ✅ 출력 제거 (CoreML 변환 대상에는 사용되지 않음)\n",
    "# print(\"패딩 후 데이터 크기:\", train_padded.shape)\n",
    "# print(\"✅ 텍스트 데이터셋 준비 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "268e0159-b2d3-4f3b-b03e-78c268131aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 크기: (40000, 188) (40000,)\n",
      "검증 데이터 크기: (5000, 188) (5000,)\n",
      "테스트 데이터 크기: (5000, 188) (5000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ✅ CoreML 입력용으로 최종 넘파이 배열 정리\n",
    "X_train, y_train = np.array(train_padded), np.array(train_labels)\n",
    "X_val, y_val = np.array(val_padded), np.array(val_labels)\n",
    "X_test, y_test = np.array(test_padded), np.array(test_labels)\n",
    "\n",
    "# ✅ CoreML 추론 시 사용되지 않으므로 출력은 주석 처리\n",
    "# print(\"훈련 데이터 크기:\", X_train.shape, y_train.shape) \n",
    "# print(\"검증 데이터 크기:\", X_val.shape, y_val.shape)\n",
    "# print(\"테스트 데이터 크기:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db1810f2-068f-42e7-a68a-858fe71246c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 텍스트 데이터 개수 - Train: 625, Validation: 79, Test: 79\n"
     ]
    }
   ],
   "source": [
    "# ✅ 데이터 개수 확인\n",
    "text_train_count = sum(1 for _ in train_text_ds)\n",
    "text_val_count = sum(1 for _ in val_text_ds)\n",
    "text_test_count = sum(1 for _ in test_text_ds)\n",
    "\n",
    "print(f\"📝 텍스트 데이터 개수 - Train: {text_train_count}, Validation: {text_val_count}, Test: {text_test_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9862f06e-780c-4cd3-b9cb-45272959d737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 데이터 형태: (64, 188)\n",
      "라벨 데이터 형태: (64,)\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_text_ds.take(1):\n",
    "    print(\"입력 데이터 형태:\", x.shape)\n",
    "    print(\"라벨 데이터 형태:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "742f073c-a902-4c32-9e3e-bd7d98e8c343",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer, Dense, Dropout\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "class AttentionLayer(Layer):\n",
    "    def __init__(self, dropout_rate=0.1, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = Dense(input_shape[-1], activation='tanh')\n",
    "        self.V = Dense(1)\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        # (batch, time, 1)\n",
    "        score = self.V(self.W(inputs))\n",
    "\n",
    "        # ✅ 마스킹 적용 (패딩된 부분을 attention에서 제외)\n",
    "        if mask is not None:\n",
    "            mask = tf.cast(mask, tf.float32)          # (batch, time)\n",
    "            mask = tf.expand_dims(mask, axis=-1)      # (batch, time, 1)\n",
    "            score -= (1.0 - mask) * 1e9                # 매우 작은 값으로 억제\n",
    "\n",
    "        attention_weights = K.softmax(score, axis=1)  # (batch, time, 1)\n",
    "        attention_weights = self.dropout(attention_weights)  # ✅ 드롭아웃 적용\n",
    "        context_vector = attention_weights * inputs\n",
    "        context_vector = K.sum(context_vector, axis=1)  # (batch, features)\n",
    "        return context_vector\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return None  # 출력에는 마스크 적용하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee2914e3-3282-401f-9a89-d00caf97634c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/mambaforge/base/envs/tf_metal/lib/python3.10/site-packages/keras/src/layers/layer.py:939: UserWarning: Layer 'conv1d_1' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)        │    <span style=\"color: #00af00; text-decoration-color: #00af00\">12,642,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">57,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ attention_layer_1               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,049</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AttentionLayer</span>)                │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">455</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m, \u001b[38;5;34m300\u001b[0m)        │    \u001b[38;5;34m12,642,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m57,664\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ attention_layer_1               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m66,049\u001b[0m │\n",
       "│ (\u001b[38;5;33mAttentionLayer\u001b[0m)                │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │           \u001b[38;5;34m455\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,980,504</span> (49.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,980,504\u001b[0m (49.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,980,376</span> (49.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,980,376\u001b[0m (49.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Embedding, Conv1D, BatchNormalization, LSTM, Bidirectional, Dropout, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# 하이퍼파라미터 기본 설정\n",
    "MAX_VOCAB_SIZE = len(tokenizer.word_index) + 1   # 어휘 사전 크기\n",
    "EMBEDDING_DIM = 300       # 줄인 임베딩 차원\n",
    "MAX_SEQUENCE_LENGTH = 98 # 문장 최대 길이\n",
    "\n",
    "# 1. 모델 생성 함수 정의 (간소화된 CNN + Bi-LSTM 구조)\n",
    "def create_model(num_filters=64, kernel_size=3, lstm_units=128, dropout_rate=0.3, learning_rate=0.00023853):\n",
    "    model = Sequential()\n",
    "    # 입력 모양 명시\n",
    "    model.add(Input(shape=(MAX_SEQUENCE_LENGTH,)))\n",
    "    # 임베딩 레이어 (input_length 제거)\n",
    "    model.add(Embedding(input_dim=MAX_VOCAB_SIZE, output_dim=EMBEDDING_DIM, mask_zero=True))\n",
    "    \n",
    "    # CNN 레이어: 필터 수를 32로 줄임\n",
    "    model.add(Conv1D(filters=num_filters, kernel_size=kernel_size, activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    # 단일 Bidirectional LSTM 레이어 사용 (출력 시퀀스 대신 최종 출력만 사용)\n",
    "    model.add(Bidirectional(LSTM(lstm_units, return_sequences=True)))\n",
    "\n",
    "    #🔑Attention 메커니즘 추가\n",
    "    model.add(AttentionLayer())\n",
    "\n",
    "    # ✅ AttentionLayer 제거 시 처리 필요\n",
    "    #model.add(tf.keras.layers.GlobalAveragePooling1D())  # 🔑 시퀀스 제거 (중요)\n",
    "    \n",
    "    # 드롭아웃 및 Dense 레이어\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(7, activation='softmax'))  # 7개의 감정 클래스\n",
    "\n",
    "    # 옵티마이저 설정 (Adam)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, clipnorm=1.0) # clipnorm 추가 (accuracy 급락 방지)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 예시로 모델 생성 및 요약 출력\n",
    "model = create_model(num_filters=64, kernel_size=3, lstm_units=128, dropout_rate=0.3,\n",
    "                     learning_rate=0.00023853)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6e2b8c6b-7bc5-4e09-8db3-30f168d90663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 Training model 1/7 (seed=42)...\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/mambaforge/base/envs/tf_metal/lib/python3.10/site-packages/keras/src/layers/layer.py:939: UserWarning: Layer 'conv1d_43' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 116ms/step - accuracy: 0.3327 - loss: 1.6813 - val_accuracy: 0.5344 - val_loss: 1.3719 - learning_rate: 3.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 117ms/step - accuracy: 0.5193 - loss: 1.3368 - val_accuracy: 0.4970 - val_loss: 1.4150 - learning_rate: 3.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.6472 - loss: 0.9126\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 117ms/step - accuracy: 0.6472 - loss: 0.9125 - val_accuracy: 0.4934 - val_loss: 1.4967 - learning_rate: 3.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 118ms/step - accuracy: 0.7766 - loss: 0.5206 - val_accuracy: 0.5050 - val_loss: 1.6440 - learning_rate: 1.5000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.8529 - loss: 0.3341\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 117ms/step - accuracy: 0.8529 - loss: 0.3340 - val_accuracy: 0.5326 - val_loss: 1.8039 - learning_rate: 1.5000e-04\n",
      "\n",
      "🔁 Training model 2/7 (seed=43)...\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/mambaforge/base/envs/tf_metal/lib/python3.10/site-packages/keras/src/layers/layer.py:939: UserWarning: Layer 'conv1d_44' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 120ms/step - accuracy: 0.2557 - loss: 1.7194 - val_accuracy: 0.5222 - val_loss: 1.3410 - learning_rate: 3.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 119ms/step - accuracy: 0.4799 - loss: 1.3949 - val_accuracy: 0.5102 - val_loss: 1.3503 - learning_rate: 3.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6269 - loss: 0.9699\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 119ms/step - accuracy: 0.6269 - loss: 0.9698 - val_accuracy: 0.4896 - val_loss: 1.4756 - learning_rate: 3.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 119ms/step - accuracy: 0.7611 - loss: 0.5734 - val_accuracy: 0.5544 - val_loss: 1.5116 - learning_rate: 1.5000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.8406 - loss: 0.3626\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 120ms/step - accuracy: 0.8406 - loss: 0.3625 - val_accuracy: 0.5290 - val_loss: 1.7591 - learning_rate: 1.5000e-04\n",
      "\n",
      "🔁 Training model 3/7 (seed=44)...\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/mambaforge/base/envs/tf_metal/lib/python3.10/site-packages/keras/src/layers/layer.py:939: UserWarning: Layer 'conv1d_45' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 120ms/step - accuracy: 0.2739 - loss: 1.7044 - val_accuracy: 0.4492 - val_loss: 1.5268 - learning_rate: 3.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.4975 - loss: 1.3627 - val_accuracy: 0.4958 - val_loss: 1.3550 - learning_rate: 3.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 121ms/step - accuracy: 0.6308 - loss: 0.9528 - val_accuracy: 0.4680 - val_loss: 1.5184 - learning_rate: 3.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.7464 - loss: 0.5882\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 120ms/step - accuracy: 0.7465 - loss: 0.5881 - val_accuracy: 0.5278 - val_loss: 1.5509 - learning_rate: 3.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 118ms/step - accuracy: 0.8466 - loss: 0.3348 - val_accuracy: 0.5416 - val_loss: 1.7578 - learning_rate: 1.5000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.9060 - loss: 0.2053\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 118ms/step - accuracy: 0.9061 - loss: 0.2052 - val_accuracy: 0.5428 - val_loss: 2.0138 - learning_rate: 1.5000e-04\n",
      "\n",
      "🔁 Training model 4/7 (seed=45)...\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/mambaforge/base/envs/tf_metal/lib/python3.10/site-packages/keras/src/layers/layer.py:939: UserWarning: Layer 'conv1d_46' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 117ms/step - accuracy: 0.2254 - loss: 1.7042 - val_accuracy: 0.5094 - val_loss: 1.5321 - learning_rate: 3.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 116ms/step - accuracy: 0.5032 - loss: 1.3415 - val_accuracy: 0.5258 - val_loss: 1.3671 - learning_rate: 3.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 117ms/step - accuracy: 0.6350 - loss: 0.9655 - val_accuracy: 0.5408 - val_loss: 1.5149 - learning_rate: 3.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.7641 - loss: 0.5837\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 119ms/step - accuracy: 0.7642 - loss: 0.5836 - val_accuracy: 0.5466 - val_loss: 1.6704 - learning_rate: 3.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 121ms/step - accuracy: 0.8587 - loss: 0.3353 - val_accuracy: 0.5564 - val_loss: 1.7933 - learning_rate: 1.5000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.9062 - loss: 0.2115\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.9062 - loss: 0.2114 - val_accuracy: 0.5552 - val_loss: 2.0931 - learning_rate: 1.5000e-04\n",
      "\n",
      "🔁 Training model 5/7 (seed=46)...\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/mambaforge/base/envs/tf_metal/lib/python3.10/site-packages/keras/src/layers/layer.py:939: UserWarning: Layer 'conv1d_47' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 122ms/step - accuracy: 0.2097 - loss: 1.7430 - val_accuracy: 0.3728 - val_loss: 1.6051 - learning_rate: 3.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.4766 - loss: 1.4627 - val_accuracy: 0.4500 - val_loss: 1.4911 - learning_rate: 3.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.6123 - loss: 1.0789 - val_accuracy: 0.4798 - val_loss: 1.5109 - learning_rate: 3.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.7354 - loss: 0.7366\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.7354 - loss: 0.7364 - val_accuracy: 0.4942 - val_loss: 1.6606 - learning_rate: 3.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 129ms/step - accuracy: 0.8302 - loss: 0.4461 - val_accuracy: 0.5082 - val_loss: 1.7959 - learning_rate: 1.5000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.8922 - loss: 0.2791\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 138ms/step - accuracy: 0.8922 - loss: 0.2790 - val_accuracy: 0.5018 - val_loss: 2.0777 - learning_rate: 1.5000e-04\n",
      "\n",
      "🔁 Training model 6/7 (seed=47)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/mambaforge/base/envs/tf_metal/lib/python3.10/site-packages/keras/src/layers/layer.py:939: UserWarning: Layer 'conv1d_48' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 135ms/step - accuracy: 0.3002 - loss: 1.6740 - val_accuracy: 0.4284 - val_loss: 1.5862 - learning_rate: 3.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 135ms/step - accuracy: 0.5318 - loss: 1.3131 - val_accuracy: 0.5054 - val_loss: 1.4004 - learning_rate: 3.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 136ms/step - accuracy: 0.6767 - loss: 0.8660 - val_accuracy: 0.4982 - val_loss: 1.5086 - learning_rate: 3.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.7946 - loss: 0.4902\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 136ms/step - accuracy: 0.7946 - loss: 0.4901 - val_accuracy: 0.4898 - val_loss: 1.7512 - learning_rate: 3.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 137ms/step - accuracy: 0.8796 - loss: 0.2703 - val_accuracy: 0.5372 - val_loss: 1.8588 - learning_rate: 1.5000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.9282 - loss: 0.1607\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 136ms/step - accuracy: 0.9282 - loss: 0.1607 - val_accuracy: 0.5350 - val_loss: 2.1627 - learning_rate: 1.5000e-04\n",
      "\n",
      "🔁 Training model 7/7 (seed=48)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/mambaforge/base/envs/tf_metal/lib/python3.10/site-packages/keras/src/layers/layer.py:939: UserWarning: Layer 'conv1d_49' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 135ms/step - accuracy: 0.2586 - loss: 1.7056 - val_accuracy: 0.3044 - val_loss: 1.7824 - learning_rate: 3.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 135ms/step - accuracy: 0.5114 - loss: 1.3468 - val_accuracy: 0.4420 - val_loss: 1.5654 - learning_rate: 3.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 134ms/step - accuracy: 0.6406 - loss: 0.9119 - val_accuracy: 0.5102 - val_loss: 1.4751 - learning_rate: 3.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 136ms/step - accuracy: 0.7642 - loss: 0.5473 - val_accuracy: 0.5214 - val_loss: 1.6432 - learning_rate: 3.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.8586 - loss: 0.3250\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 137ms/step - accuracy: 0.8586 - loss: 0.3250 - val_accuracy: 0.4912 - val_loss: 2.1140 - learning_rate: 3.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 138ms/step - accuracy: 0.9170 - loss: 0.1788 - val_accuracy: 0.5288 - val_loss: 2.1083 - learning_rate: 1.5000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.9572 - loss: 0.0978\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 137ms/step - accuracy: 0.9572 - loss: 0.0978 - val_accuracy: 0.5350 - val_loss: 2.4609 - learning_rate: 1.5000e-04\n"
     ]
    }
   ],
   "source": [
    "# 2. 미리 정해진(best) 하이퍼파라미터 설정 (Grid Search 없이 직접 지정)\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# 클래스 가중치 계산\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "# 가중치 제한 (너무 큰 가중치 방지)\n",
    "max_weight_limit = 7   # 10에서 변경 \n",
    "adjusted_weights = np.clip(class_weights, 0, max_weight_limit)\n",
    "\n",
    "class_weights_dict = dict(enumerate(adjusted_weights))\n",
    "\n",
    "best_params = {\n",
    "    'num_filters': 64, # 높을수록 과적합 32에서 변경\n",
    "    'kernel_size': 3, # 고정\n",
    "    'lstm_units': 128,  # 높을수록 과적합\n",
    "    'dropout_rate': 0.3, \n",
    "    'learning_rate': 0.0003, \n",
    "    'epochs': 50, # 고정\n",
    "    'batch_size': 64 # 높을수록 과적합 64에서 변경\n",
    "}\n",
    "\n",
    "# 3. 앙상블 학습: 동일한 하이퍼파라미터로 여러 모델을 개별 학습시킴\n",
    "ensemble_models = []\n",
    "histories = []\n",
    "n_ensemble = 7  # 사용할 모델 개수 5에서 변경\n",
    "\n",
    "# 🔑 EarlyStopping 및 ReduceLROnPlateau 설정 추가\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)\n",
    "\n",
    "for i in range(n_ensemble):\n",
    "    print(f\"\\n🔁 Training model {i+1}/{n_ensemble} (seed={42 + i})...\")\n",
    "\n",
    "    # ✅ seed 고정 (가중치 + 셔플 + NumPy 일관성)\n",
    "    tf.keras.utils.set_random_seed(42 + i)\n",
    "    \n",
    "    model = create_model(num_filters=best_params['num_filters'],\n",
    "                         kernel_size=best_params['kernel_size'],\n",
    "                         lstm_units=best_params['lstm_units'],\n",
    "                         dropout_rate=best_params['dropout_rate'],\n",
    "                         learning_rate=best_params['learning_rate'])\n",
    "    history = model.fit(X_train, y_train, \n",
    "                  epochs=best_params['epochs'], \n",
    "                  batch_size=best_params['batch_size'], \n",
    "                  validation_data = (X_val, y_val),\n",
    "                  callbacks=[early_stop, lr_scheduler],\n",
    "                  class_weight=class_weights_dict,\n",
    "                  verbose=1\n",
    "    )\n",
    "    ensemble_models.append(model)\n",
    "    histories.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cf88b959-c6d8-4875-8c97-66076d851caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 1: 최고 검증 정확도 = 0.5344\n",
      "모델 2: 최고 검증 정확도 = 0.5544\n",
      "모델 3: 최고 검증 정확도 = 0.5428\n",
      "모델 4: 최고 검증 정확도 = 0.5564\n",
      "모델 5: 최고 검증 정확도 = 0.5082\n",
      "모델 6: 최고 검증 정확도 = 0.5372\n",
      "모델 7: 최고 검증 정확도 = 0.5350\n",
      "\n",
      "선택된 모델: 모델 4 (검증 정확도: 0.5564)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Average\n",
    "\n",
    "# ✅ 입력 정의 (기존과 동일한 시퀀스 길이)\n",
    "ensemble_input = Input(shape=(MAX_SEQUENCE_LENGTH,), name=\"text_input\")\n",
    "\n",
    "# ✅ 모든 앙상블 모델들의 출력 계산\n",
    "model_outputs = [model(ensemble_input) for model in ensemble_models]\n",
    "\n",
    "# ✅ softmax 평균\n",
    "avg_output = Average()(model_outputs)\n",
    "\n",
    "# ✅ 최종 모델 정의\n",
    "ensemble_model = Model(inputs=ensemble_input, outputs=avg_output)\n",
    "\n",
    "# ✅ .h5로 저장 (CoreML 변환을 위해 이 파일을 사용)\n",
    "ensemble_model.save(\"text_ensemble_model.h5\")\n",
    "print(\"✅ 앙상블 평균 모델 저장 완료: text_ensemble_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_metal)",
   "language": "python",
   "name": "tf_metal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
