{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dcd155e-23ad-4a5d-92b8-db0db422b67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # ê²½ê³ (W) ë©”ì‹œì§€ë§Œ ìˆ¨ê¹€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65d8b071-1b93-4d19-b8ec-3d0549e87d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf14af21-206c-4d92-9019-734e5917162f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU ë©”ëª¨ë¦¬ ë™ì  í• ë‹¹ í™œì„±í™” ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# GPU í™˜ê²½ì´ ì•„ë‹Œ CoreMLì—ì„œëŠ” ì´ ì„¤ì •ì´ í•„ìš” ì—†ìŒ\n",
    "# ë”°ë¼ì„œ ë³€í™˜ ì‹œ ì£¼ì„ ì²˜ë¦¬í•˜ê±°ë‚˜ ì‚­ì œ ê°€ëŠ¥\n",
    "# ë‹¨, ë¡œì»¬ í•™ìŠµ ì‹œì—ëŠ” ìœ ì§€ ê°€ëŠ¥í•˜ë¯€ë¡œ ì¡°ê±´ ë¶„ê¸° ì²˜ë¦¬\n",
    "import platform\n",
    "if platform.system() != 'Darwin':\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(\"GPU ë©”ëª¨ë¦¬ ë™ì  í• ë‹¹ í™œì„±í™” ì™„ë£Œ\")\n",
    "        except RuntimeError as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4bb29387-ac0b-45ac-9625-1dfe66e618ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ë°ì´í„° í¬ê¸°: (39999, 3)\n",
      "Test ë°ì´í„° í¬ê¸°: (4999, 3)\n",
      "Validation ë°ì´í„° í¬ê¸°: (4999, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>39087</th>\n",
       "      <th>ë‚´ê°€ í†°í–‰í¬ìŠ¤ë¥¼ ì¢‹ì•„í•˜ê¸´ í–ˆë‚˜ë³´ë‹¤... ì´ˆê¸° ì˜í™” ë¹¼ê³ ëŠ” ë‹¤ ë´¤ë„¤.</th>\n",
       "      <th>2,13,15,16,29,39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30893</td>\n",
       "      <td>ì •ë§ ìƒìƒì„ ì´ˆì›”í•˜ëŠ” ë¬´ê°œë… ì§„ìƒë“¤ ìƒëŒ€í•˜ë‹¤ ìš°ìš¸ì¦, ê³µí•­ì¥ì•  ê±¸ë¦¬ëŠ” ê³µë¬´ì› ë§ì•„ìš”...</td>\n",
       "      <td>0,5,7,10,19,22,29,35,36,38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45278</td>\n",
       "      <td>ìƒˆë¡œìš´ ì„¸ìƒê³¼ ì¡°ìš°í•œ ìì˜ ì–´ë¦°ì•„ì´ ê°™ì€ ë°˜ì‘, ì–´ì©Œë©´ íšŒë³µëœ ê²ƒì€ ëˆˆì´ ì•„ë‹Œ ìˆœìˆ˜...</td>\n",
       "      <td>1,2,7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16398</td>\n",
       "      <td>ë¯¸ì—­ì€ ì›ìƒìƒë¬¼ê³„ ì‚°í˜¸ì´ˆëŠ” ë™ë¬¼ã…‡ã…‡ ì•„ ë¯¸ì—­ì´ ë°”ë‹¤ì˜ ìƒˆã„±ã…‡ã„±ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹</td>\n",
       "      <td>9,15,20,23,26,28,29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13653</td>\n",
       "      <td>ë„¤ ë§ìŠµë‹ˆë‹¤ í”ŒìŠ¤ëŠ” ì—­ì‹œ 30í”„ë ˆì„ì´ ì–´ìš¸ë¦¬ì£  ã…</td>\n",
       "      <td>1,2,8,9,11,13,15,16,28,29,32,40,42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13748</td>\n",
       "      <td>ì–´ë¦´ ë•Œ í–ˆë˜ ê±´ë° ì•„ì§ë„ ë³¼ ë•Œë§ˆë‹¤ ë’¤í†µìˆ˜ ì–¼ì–¼í•¨ ã…‹ã…‹ã…‹ã…‹</td>\n",
       "      <td>2,15,23,24,25,28,33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   39087              ë‚´ê°€ í†°í–‰í¬ìŠ¤ë¥¼ ì¢‹ì•„í•˜ê¸´ í–ˆë‚˜ë³´ë‹¤... ì´ˆê¸° ì˜í™” ë¹¼ê³ ëŠ” ë‹¤ ë´¤ë„¤.  \\\n",
       "0  30893  ì •ë§ ìƒìƒì„ ì´ˆì›”í•˜ëŠ” ë¬´ê°œë… ì§„ìƒë“¤ ìƒëŒ€í•˜ë‹¤ ìš°ìš¸ì¦, ê³µí•­ì¥ì•  ê±¸ë¦¬ëŠ” ê³µë¬´ì› ë§ì•„ìš”...   \n",
       "1  45278  ìƒˆë¡œìš´ ì„¸ìƒê³¼ ì¡°ìš°í•œ ìì˜ ì–´ë¦°ì•„ì´ ê°™ì€ ë°˜ì‘, ì–´ì©Œë©´ íšŒë³µëœ ê²ƒì€ ëˆˆì´ ì•„ë‹Œ ìˆœìˆ˜...   \n",
       "2  16398       ë¯¸ì—­ì€ ì›ìƒìƒë¬¼ê³„ ì‚°í˜¸ì´ˆëŠ” ë™ë¬¼ã…‡ã…‡ ì•„ ë¯¸ì—­ì´ ë°”ë‹¤ì˜ ìƒˆã„±ã…‡ã„±ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹   \n",
       "3  13653                        ë„¤ ë§ìŠµë‹ˆë‹¤ í”ŒìŠ¤ëŠ” ì—­ì‹œ 30í”„ë ˆì„ì´ ì–´ìš¸ë¦¬ì£  ã…   \n",
       "4  13748                  ì–´ë¦´ ë•Œ í–ˆë˜ ê±´ë° ì•„ì§ë„ ë³¼ ë•Œë§ˆë‹¤ ë’¤í†µìˆ˜ ì–¼ì–¼í•¨ ã…‹ã…‹ã…‹ã…‹   \n",
       "\n",
       "                     2,13,15,16,29,39  \n",
       "0          0,5,7,10,19,22,29,35,36,38  \n",
       "1                               1,2,7  \n",
       "2                 9,15,20,23,26,28,29  \n",
       "3  1,2,8,9,11,13,15,16,28,29,32,40,42  \n",
       "4                 2,15,23,24,25,28,33  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# KOTE ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "train_df = pd.read_csv(\"KOTE/train.tsv\", sep='\\t')\n",
    "test_df = pd.read_csv(\"KOTE/test.tsv\", sep='\\t')\n",
    "val_df = pd.read_csv(\"KOTE/val.tsv\", sep='\\t')\n",
    "\n",
    "# ë°ì´í„° í™•ì¸\n",
    "print(f\"Train ë°ì´í„° í¬ê¸°: {train_df.shape}\")\n",
    "print(f\"Test ë°ì´í„° í¬ê¸°: {test_df.shape}\")\n",
    "print(f\"Validation ë°ì´í„° í¬ê¸°: {val_df.shape}\")\n",
    "\n",
    "# ë°ì´í„° ìƒ˜í”Œ ì¶œë ¥\n",
    "#train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ca065fe-7fbd-48c4-88c1-7df08a0ee135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id                                           comments  \\\n",
      "0  39087              ë‚´ê°€ í†°í–‰í¬ìŠ¤ë¥¼ ì¢‹ì•„í•˜ê¸´ í–ˆë‚˜ë³´ë‹¤... ì´ˆê¸° ì˜í™” ë¹¼ê³ ëŠ” ë‹¤ ë´¤ë„¤.   \n",
      "1  30893  ì •ë§ ìƒìƒì„ ì´ˆì›”í•˜ëŠ” ë¬´ê°œë… ì§„ìƒë“¤ ìƒëŒ€í•˜ë‹¤ ìš°ìš¸ì¦, ê³µí•­ì¥ì•  ê±¸ë¦¬ëŠ” ê³µë¬´ì› ë§ì•„ìš”...   \n",
      "2  45278  ìƒˆë¡œìš´ ì„¸ìƒê³¼ ì¡°ìš°í•œ ìì˜ ì–´ë¦°ì•„ì´ ê°™ì€ ë°˜ì‘, ì–´ì©Œë©´ íšŒë³µëœ ê²ƒì€ ëˆˆì´ ì•„ë‹Œ ìˆœìˆ˜...   \n",
      "3  16398       ë¯¸ì—­ì€ ì›ìƒìƒë¬¼ê³„ ì‚°í˜¸ì´ˆëŠ” ë™ë¬¼ã…‡ã…‡ ì•„ ë¯¸ì—­ì´ ë°”ë‹¤ì˜ ìƒˆã„±ã…‡ã„±ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹   \n",
      "4  13653                        ë„¤ ë§ìŠµë‹ˆë‹¤ í”ŒìŠ¤ëŠ” ì—­ì‹œ 30í”„ë ˆì„ì´ ì–´ìš¸ë¦¬ì£  ã…   \n",
      "\n",
      "                               labels  \n",
      "0                    2,13,15,16,29,39  \n",
      "1          0,5,7,10,19,22,29,35,36,38  \n",
      "2                               1,2,7  \n",
      "3                 9,15,20,23,26,28,29  \n",
      "4  1,2,8,9,11,13,15,16,28,29,32,40,42  \n",
      "ğŸ“Œ ë°ì´í„° ì»¬ëŸ¼ ëª©ë¡: Index(['id', 'comments', 'labels'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# âœ… CoreML ë³€í™˜ê³¼ ì§ì ‘ ê´€ë ¨ì€ ì—†ì§€ë§Œ, ë³€í™˜ ëŒ€ìƒ ëª¨ë¸ í•™ìŠµì— í•„ìš”í•œ ë°ì´í„° ì „ì²˜ë¦¬ ë‹¨ê³„ì´ë¯€ë¡œ ìœ ì§€\n",
    "train_df = pd.read_csv(\"KOTE/train.tsv\", sep='\\t', names=['id', 'comments', 'labels'], header=None)\n",
    "test_df = pd.read_csv(\"KOTE/test.tsv\", sep='\\t', names=['id', 'comments', 'labels'], header=None)\n",
    "val_df = pd.read_csv(\"KOTE/val.tsv\", sep='\\t', names=['id', 'comments', 'labels'], header=None)\n",
    "\n",
    "# âœ… ë³€í™˜ í›„ì—ëŠ” ì¶œë ¥ì´ í•„ìš” ì—†ìœ¼ë¯€ë¡œ ì£¼ì„ ì²˜ë¦¬í•˜ê±°ë‚˜ ì‚­ì œ\n",
    "# print(train_df.head())\n",
    "# print(\"ğŸ“Œ ë°ì´í„° ì»¬ëŸ¼ ëª©ë¡:\", train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2bcd9a8e-b270-4309-90bb-d36224269719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ë‚´ê°€ í†°í–‰í¬ìŠ¤ë¥¼ ì¢‹ì•„í•˜ê¸´ í–ˆë‚˜ë³´ë‹¤... ì´ˆê¸° ì˜í™” ë¹¼ê³ ëŠ” ë‹¤ ë´¤ë„¤.</td>\n",
       "      <td>ë‚´ê°€ í†°í–‰í¬ìŠ¤ë¥¼ ì¢‹ì•„í•˜ê¸´ í–ˆë‚˜ë³´ë‹¤ ì´ˆê¸° ì˜í™” ë¹¼ê³ ëŠ” ë‹¤ ë´¤ë„¤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ì •ë§ ìƒìƒì„ ì´ˆì›”í•˜ëŠ” ë¬´ê°œë… ì§„ìƒë“¤ ìƒëŒ€í•˜ë‹¤ ìš°ìš¸ì¦, ê³µí•­ì¥ì•  ê±¸ë¦¬ëŠ” ê³µë¬´ì› ë§ì•„ìš”...</td>\n",
       "      <td>ì •ë§ ìƒìƒì„ ì´ˆì›”í•˜ëŠ” ë¬´ê°œë… ì§„ìƒë“¤ ìƒëŒ€í•˜ë‹¤ ìš°ìš¸ì¦ ê³µí•­ì¥ì•  ê±¸ë¦¬ëŠ” ê³µë¬´ì› ë§ì•„ìš” ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ìƒˆë¡œìš´ ì„¸ìƒê³¼ ì¡°ìš°í•œ ìì˜ ì–´ë¦°ì•„ì´ ê°™ì€ ë°˜ì‘, ì–´ì©Œë©´ íšŒë³µëœ ê²ƒì€ ëˆˆì´ ì•„ë‹Œ ìˆœìˆ˜...</td>\n",
       "      <td>ìƒˆë¡œìš´ ì„¸ìƒê³¼ ì¡°ìš°í•œ ìì˜ ì–´ë¦°ì•„ì´ ê°™ì€ ë°˜ì‘ ì–´ì©Œë©´ íšŒë³µëœ ê²ƒì€ ëˆˆì´ ì•„ë‹Œ ìˆœìˆ˜í•¨...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ë¯¸ì—­ì€ ì›ìƒìƒë¬¼ê³„ ì‚°í˜¸ì´ˆëŠ” ë™ë¬¼ã…‡ã…‡ ì•„ ë¯¸ì—­ì´ ë°”ë‹¤ì˜ ìƒˆã„±ã…‡ã„±ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹</td>\n",
       "      <td>ë¯¸ì—­ì€ ì›ìƒìƒë¬¼ê³„ ì‚°í˜¸ì´ˆëŠ” ë™ë¬¼ã…‡ã…‡ ì•„ ë¯¸ì—­ì´ ë°”ë‹¤ì˜ ìƒˆã„±ã…‡ã„±ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ë„¤ ë§ìŠµë‹ˆë‹¤ í”ŒìŠ¤ëŠ” ì—­ì‹œ 30í”„ë ˆì„ì´ ì–´ìš¸ë¦¬ì£  ã…</td>\n",
       "      <td>ë„¤ ë§ìŠµë‹ˆë‹¤ í”ŒìŠ¤ëŠ” ì—­ì‹œ 30í”„ë ˆì„ì´ ì–´ìš¸ë¦¬ì£  ã…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ì–´ë¦´ ë•Œ í–ˆë˜ ê±´ë° ì•„ì§ë„ ë³¼ ë•Œë§ˆë‹¤ ë’¤í†µìˆ˜ ì–¼ì–¼í•¨ ã…‹ã…‹ã…‹ã…‹</td>\n",
       "      <td>ì–´ë¦´ ë•Œ í–ˆë˜ ê±´ë° ì•„ì§ë„ ë³¼ ë•Œë§ˆë‹¤ ë’¤í†µìˆ˜ ì–¼ì–¼í•¨ ã…‹ã…‹ã…‹ã…‹</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ë¬¼ê°ˆì´ì•½ êµ¬ë§¤í–ˆì–´ìš”...ë¯¸ë¯¸ë„¤ì—ì„œ ìˆ˜ì¡°2ê°œë‘ ì—¬ëŸ¬ê°€ì§€ ìš©í’ˆì‚¬ë©´ì„œ 3~4ë²ˆ ì£¼ë¬¸í–ˆì—ˆëŠ”...</td>\n",
       "      <td>ë¬¼ê°ˆì´ì•½ êµ¬ë§¤í–ˆì–´ìš”ë¯¸ë¯¸ë„¤ì—ì„œ ìˆ˜ì¡°2ê°œë‘ ì—¬ëŸ¬ê°€ì§€ ìš©í’ˆì‚¬ë©´ì„œ 34ë²ˆ ì£¼ë¬¸í–ˆì—ˆëŠ”ë° ê·¸ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ì‹­ì¼ì¡°ëŠ” ê²¨ìš°60ì¸ë°? ë‚˜ë¨¸ì§€ ë‹¤ ì–´ë””ê°? í˜¹ì‹œ ì—„ë§ˆì•„ë¹  ê·¸ëœì ¸ë”°ë¡œíƒ€ê³ , ì™¸ì‹ìì£¼í•˜...</td>\n",
       "      <td>ì‹­ì¼ì¡°ëŠ” ê²¨ìš°60ì¸ë° ë‚˜ë¨¸ì§€ ë‹¤ ì–´ë””ê° í˜¹ì‹œ ì—„ë§ˆì•„ë¹  ê·¸ëœì ¸ë”°ë¡œíƒ€ê³  ì™¸ì‹ìì£¼í•˜ëŠ”ê±°ì•„...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>90ë…„ ì¤˜ì•¼ í•˜ëŠ”ê±° ì•„ë‹Œê°€?  ì“°ë ˆê¸°ê°™ì€ ê²ƒë“¤.</td>\n",
       "      <td>90ë…„ ì¤˜ì•¼ í•˜ëŠ”ê±° ì•„ë‹Œê°€ ì“°ë ˆê¸°ê°™ì€ ê²ƒë“¤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ì•„ì£¼ ë¶€ì°©ì„±ë„ ì¢‹ê³  íš¨ê³¼ 100ì  ì…ë‹ˆë‹¤</td>\n",
       "      <td>ì•„ì£¼ ë¶€ì°©ì„±ë„ ì¢‹ê³  íš¨ê³¼ 100ì  ì…ë‹ˆë‹¤</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments  \\\n",
       "0              ë‚´ê°€ í†°í–‰í¬ìŠ¤ë¥¼ ì¢‹ì•„í•˜ê¸´ í–ˆë‚˜ë³´ë‹¤... ì´ˆê¸° ì˜í™” ë¹¼ê³ ëŠ” ë‹¤ ë´¤ë„¤.   \n",
       "1  ì •ë§ ìƒìƒì„ ì´ˆì›”í•˜ëŠ” ë¬´ê°œë… ì§„ìƒë“¤ ìƒëŒ€í•˜ë‹¤ ìš°ìš¸ì¦, ê³µí•­ì¥ì•  ê±¸ë¦¬ëŠ” ê³µë¬´ì› ë§ì•„ìš”...   \n",
       "2  ìƒˆë¡œìš´ ì„¸ìƒê³¼ ì¡°ìš°í•œ ìì˜ ì–´ë¦°ì•„ì´ ê°™ì€ ë°˜ì‘, ì–´ì©Œë©´ íšŒë³µëœ ê²ƒì€ ëˆˆì´ ì•„ë‹Œ ìˆœìˆ˜...   \n",
       "3       ë¯¸ì—­ì€ ì›ìƒìƒë¬¼ê³„ ì‚°í˜¸ì´ˆëŠ” ë™ë¬¼ã…‡ã…‡ ì•„ ë¯¸ì—­ì´ ë°”ë‹¤ì˜ ìƒˆã„±ã…‡ã„±ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹   \n",
       "4                        ë„¤ ë§ìŠµë‹ˆë‹¤ í”ŒìŠ¤ëŠ” ì—­ì‹œ 30í”„ë ˆì„ì´ ì–´ìš¸ë¦¬ì£  ã…   \n",
       "5                  ì–´ë¦´ ë•Œ í–ˆë˜ ê±´ë° ì•„ì§ë„ ë³¼ ë•Œë§ˆë‹¤ ë’¤í†µìˆ˜ ì–¼ì–¼í•¨ ã…‹ã…‹ã…‹ã…‹   \n",
       "6  ë¬¼ê°ˆì´ì•½ êµ¬ë§¤í–ˆì–´ìš”...ë¯¸ë¯¸ë„¤ì—ì„œ ìˆ˜ì¡°2ê°œë‘ ì—¬ëŸ¬ê°€ì§€ ìš©í’ˆì‚¬ë©´ì„œ 3~4ë²ˆ ì£¼ë¬¸í–ˆì—ˆëŠ”...   \n",
       "7  ì‹­ì¼ì¡°ëŠ” ê²¨ìš°60ì¸ë°? ë‚˜ë¨¸ì§€ ë‹¤ ì–´ë””ê°? í˜¹ì‹œ ì—„ë§ˆì•„ë¹  ê·¸ëœì ¸ë”°ë¡œíƒ€ê³ , ì™¸ì‹ìì£¼í•˜...   \n",
       "8                         90ë…„ ì¤˜ì•¼ í•˜ëŠ”ê±° ì•„ë‹Œê°€?  ì“°ë ˆê¸°ê°™ì€ ê²ƒë“¤.   \n",
       "9                             ì•„ì£¼ ë¶€ì°©ì„±ë„ ì¢‹ê³  íš¨ê³¼ 100ì  ì…ë‹ˆë‹¤   \n",
       "\n",
       "                                          clean_text  \n",
       "0                  ë‚´ê°€ í†°í–‰í¬ìŠ¤ë¥¼ ì¢‹ì•„í•˜ê¸´ í–ˆë‚˜ë³´ë‹¤ ì´ˆê¸° ì˜í™” ë¹¼ê³ ëŠ” ë‹¤ ë´¤ë„¤  \n",
       "1  ì •ë§ ìƒìƒì„ ì´ˆì›”í•˜ëŠ” ë¬´ê°œë… ì§„ìƒë“¤ ìƒëŒ€í•˜ë‹¤ ìš°ìš¸ì¦ ê³µí•­ì¥ì•  ê±¸ë¦¬ëŠ” ê³µë¬´ì› ë§ì•„ìš” ...  \n",
       "2  ìƒˆë¡œìš´ ì„¸ìƒê³¼ ì¡°ìš°í•œ ìì˜ ì–´ë¦°ì•„ì´ ê°™ì€ ë°˜ì‘ ì–´ì©Œë©´ íšŒë³µëœ ê²ƒì€ ëˆˆì´ ì•„ë‹Œ ìˆœìˆ˜í•¨...  \n",
       "3       ë¯¸ì—­ì€ ì›ìƒìƒë¬¼ê³„ ì‚°í˜¸ì´ˆëŠ” ë™ë¬¼ã…‡ã…‡ ì•„ ë¯¸ì—­ì´ ë°”ë‹¤ì˜ ìƒˆã„±ã…‡ã„±ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹  \n",
       "4                        ë„¤ ë§ìŠµë‹ˆë‹¤ í”ŒìŠ¤ëŠ” ì—­ì‹œ 30í”„ë ˆì„ì´ ì–´ìš¸ë¦¬ì£  ã…  \n",
       "5                  ì–´ë¦´ ë•Œ í–ˆë˜ ê±´ë° ì•„ì§ë„ ë³¼ ë•Œë§ˆë‹¤ ë’¤í†µìˆ˜ ì–¼ì–¼í•¨ ã…‹ã…‹ã…‹ã…‹  \n",
       "6  ë¬¼ê°ˆì´ì•½ êµ¬ë§¤í–ˆì–´ìš”ë¯¸ë¯¸ë„¤ì—ì„œ ìˆ˜ì¡°2ê°œë‘ ì—¬ëŸ¬ê°€ì§€ ìš©í’ˆì‚¬ë©´ì„œ 34ë²ˆ ì£¼ë¬¸í–ˆì—ˆëŠ”ë° ê·¸ ...  \n",
       "7  ì‹­ì¼ì¡°ëŠ” ê²¨ìš°60ì¸ë° ë‚˜ë¨¸ì§€ ë‹¤ ì–´ë””ê° í˜¹ì‹œ ì—„ë§ˆì•„ë¹  ê·¸ëœì ¸ë”°ë¡œíƒ€ê³  ì™¸ì‹ìì£¼í•˜ëŠ”ê±°ì•„...  \n",
       "8                            90ë…„ ì¤˜ì•¼ í•˜ëŠ”ê±° ì•„ë‹Œê°€ ì“°ë ˆê¸°ê°™ì€ ê²ƒë“¤  \n",
       "9                             ì•„ì£¼ ë¶€ì°©ì„±ë„ ì¢‹ê³  íš¨ê³¼ 100ì  ì…ë‹ˆë‹¤  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# í…ìŠ¤íŠ¸ ì •ì œ í•¨ìˆ˜ (ìˆ«ì ìœ ì§€)\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"[^ê°€-í£ã„±-ã…ã…-ã…£0-9\\s]\", \"\", text)  # í•œê¸€, ìˆ«ì, ê³µë°± ì œì™¸í•œ ë¬¸ì ì œê±°\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # ì—°ì†ëœ ê³µë°± ì œê±°\n",
    "    return text\n",
    "\n",
    "# âœ… CoreMLì—ì„œëŠ” í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ê°€ ë¶ˆê°€ëŠ¥í•˜ë¯€ë¡œ, ì‚¬ì „ ì •ì œëŠ” í•„ìˆ˜\n",
    "train_df['clean_text'] = train_df['comments'].apply(clean_text)\n",
    "test_df['clean_text'] = test_df['comments'].apply(clean_text)\n",
    "val_df['clean_text'] = val_df['comments'].apply(clean_text)\n",
    "\n",
    "# âœ… ì¶œë ¥ì€ í•™ìŠµìš© í™•ì¸ìš© â†’ ë³€í™˜ í›„ì—ëŠ” ì£¼ì„ ì²˜ë¦¬\n",
    "# train_df[['comments', 'clean_text']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4802127f-31d4-4891-a172-6a8077ae44a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… í…ìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "train_texts = train_df['clean_text'].tolist()\n",
    "test_texts = test_df['clean_text'].tolist()\n",
    "val_texts = val_df['clean_text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9636f8af-0a69-4d81-b617-e07ec6c6376a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels\n",
      "0,6,10,22,23,33                       125\n",
      "0,6,10,12,22,23,33                    108\n",
      "24                                     83\n",
      "2,28,40,42                             65\n",
      "0,10,22,37                             55\n",
      "                                     ... \n",
      "0,3,10,12,20,21,22,23,24,27,31,35       1\n",
      "0,5,10,19,20,22,25,27,31,36,38          1\n",
      "0,2,3,8,20,22,23,24,28,29,32,33,39      1\n",
      "1,11,14,15,16,27,29,38,39,41            1\n",
      "2,9,10,15,18,23,33,35,39                1\n",
      "Name: count, Length: 29332, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ê°ì • ë¼ë²¨ ê°œìˆ˜ í™•ì¸\n",
    "#print(train_df['labels'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b09a5a33-5f28-49ea-b351-505875ab6217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fer2013_emotion_grouped\n",
      "0    16762\n",
      "6     8879\n",
      "3     6499\n",
      "4     4150\n",
      "5     2588\n",
      "2      776\n",
      "1      346\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# ê°ì •ì„ 7ê°œ ê·¸ë£¹ìœ¼ë¡œ ì •ë¦¬í•˜ëŠ” ë§¤í•‘\n",
    "emotion_mapping = {\n",
    "    'ê¸°ì¨': [42, 40, 28],\n",
    "    'ìŠ¬í””': [5, 19, 25, 36],\n",
    "    'ë†€ëŒ': [39, 34, 15, 2],\n",
    "    'ë¶„ë…¸': [6, 22, 0],\n",
    "    'ê³µí¬': [18, 41],\n",
    "    'í˜ì˜¤': [31, 21],\n",
    "    'ì¤‘ë¦½': [24, 14, 43]\n",
    "}\n",
    "\n",
    "# FER2013 ê°ì • ì¸ë±ìŠ¤ ë§µí•‘\n",
    "fer2013_label_mapping = {\n",
    "    'ê¸°ì¨': 3, 'ìŠ¬í””': 5, 'ë†€ëŒ': 6,\n",
    "    'ë¶„ë…¸': 0, 'ê³µí¬': 2, 'í˜ì˜¤': 1, 'ì¤‘ë¦½': 4\n",
    "}\n",
    "\n",
    "def map_to_fer2013(label_str):\n",
    "    if pd.isna(label_str) or label_str == '':\n",
    "        return 4\n",
    "    label_list = list(map(int, label_str.split(',')))\n",
    "    matched_fer_labels = []\n",
    "    for num in label_list:\n",
    "        for kotem, kote_ids in emotion_mapping.items():\n",
    "            if num in kote_ids:\n",
    "                matched_fer_labels.append(fer2013_label_mapping[kotem])\n",
    "    if not matched_fer_labels:\n",
    "        return 4\n",
    "    return Counter(matched_fer_labels).most_common(1)[0][0]\n",
    "\n",
    "# ë ˆì´ë¸” ë³€í™˜ ì ìš©\n",
    "train_df['fer2013_emotion_grouped'] = train_df['labels'].fillna('').apply(map_to_fer2013)\n",
    "test_df['fer2013_emotion_grouped'] = test_df['labels'].fillna('').apply(map_to_fer2013)\n",
    "val_df['fer2013_emotion_grouped'] = val_df['labels'].fillna('').apply(map_to_fer2013)\n",
    "\n",
    "# âœ… ì¶œë ¥ì€ í•™ìŠµ ì¤‘ ë””ë²„ê¹…ìš© â†’ CoreML ë³€í™˜ ì‹œì—ëŠ” ì£¼ì„ ì²˜ë¦¬\n",
    "# print(train_df['fer2013_emotion_grouped'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71602852-08d6-4151-b5fb-737474394753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¼ë²¨ ë³€í™˜ ê²°ê³¼: [6 5 6 6 3]\n"
     ]
    }
   ],
   "source": [
    "# âœ… ê°ì • ë¼ë²¨ (FER2013 ë§¤í•‘ëœ ë¼ë²¨)\n",
    "train_labels = train_df['fer2013_emotion_grouped'].values\n",
    "test_labels = test_df['fer2013_emotion_grouped'].values\n",
    "val_labels = val_df['fer2013_emotion_grouped'].values\n",
    "\n",
    "# âœ… ì¶œë ¥ì€ í•™ìŠµ ì¤‘ í™•ì¸ìš© â†’ ë³€í™˜ í›„ì—ëŠ” ì œê±°\n",
    "# print(\"ë¼ë²¨ ë³€í™˜ ê²°ê³¼:\", train_labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ac71585-3e23-44f7-8b9b-d53900177378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename:\t/opt/homebrew/lib/mecab/dic/mecab-ko-dic/sys.dic\n",
      "version:\t102\n",
      "charset:\tUTF-8\n",
      "type:\t0\n",
      "size:\t816283\n",
      "left size:\t3822\n",
      "right size:\t2693\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# âœ… mecab ì‚¬ì „ ì •ë³´ ì¶œë ¥ì€ ê°œë°œ í™•ì¸ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©\n",
    "# CoreML í™˜ê²½ (iOS/macOS ì¶”ë¡  ì—”ì§„)ì—ì„œëŠ” ì‚¬ìš©ë˜ì§€ ì•ŠìŒ\n",
    "# !mecab -D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6af99fc0-b1e4-4c4b-920e-c4e7d0eb2523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… MECAB í™˜ê²½ ì„¤ì • (ë¡œì»¬ í•™ìŠµ ì‹œì—ëŠ” í•„ìš”í•˜ë‚˜, CoreML ë³€í™˜ í›„ì—ëŠ” ë¶ˆí•„ìš”)\n",
    "# CoreMLì—ëŠ” í† í¬ë‚˜ì´ì € í¬í•¨ ë¶ˆê°€í•˜ë¯€ë¡œ ì…ë ¥ ì‹œí€€ìŠ¤ëŠ” ì‚¬ì „ì— ë³€í™˜ë˜ì–´ì•¼ í•¨\n",
    "import os\n",
    "os.environ[\"MECABRC\"] = \"/opt/homebrew/etc/mecabrc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a43a3a42-f0d9-477e-be4e-9f067d55140f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ì´', 'ë¬¸ì¥', 'ì€', 'í˜•íƒœì†Œ', 'ë¶„ì„', 'ì„', 'í…ŒìŠ¤íŠ¸', 'í•˜', 'ëŠ”', 'ë¬¸ì¥', 'ì…ë‹ˆë‹¤', '.']\n"
     ]
    }
   ],
   "source": [
    "# âœ… mecab í˜•íƒœì†Œ ë¶„ì„ê¸°ëŠ” CoreML í™˜ê²½ì—ì„œëŠ” ì‚¬ìš© ë¶ˆê°€\n",
    "# í•™ìŠµ ì‹œì—ëŠ” ì‚¬ìš© ê°€ëŠ¥ â†’ ë³€í™˜ëœ ì…ë ¥ ì‹œí€€ìŠ¤ë¥¼ .npyë¡œ ì €ì¥í•˜ì—¬ ëª¨ë¸ì— ê³µê¸‰í•´ì•¼ í•¨\n",
    "\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "# ë¡œì»¬ í•™ìŠµìš© mecab ì´ˆê¸°í™”\n",
    "mecab = Mecab(dicpath='/opt/homebrew/lib/mecab/dic/mecab-ko-dic')\n",
    "\n",
    "# âœ… í…ŒìŠ¤íŠ¸ ì¶œë ¥ì€ CoreML ë³€í™˜ ì´í›„ì—ëŠ” ì œê±°\n",
    "# print(mecab.morphs(\"ì´ ë¬¸ì¥ì€ í˜•íƒœì†Œ ë¶„ì„ì„ í…ŒìŠ¤íŠ¸í•˜ëŠ” ë¬¸ì¥ì…ë‹ˆë‹¤.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "14e54bf0-28ba-41ae-a051-4c347d0fa577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          clean_text  \\\n",
      "0                  ë‚´ê°€ í†°í–‰í¬ìŠ¤ë¥¼ ì¢‹ì•„í•˜ê¸´ í–ˆë‚˜ë³´ë‹¤ ì´ˆê¸° ì˜í™” ë¹¼ê³ ëŠ” ë‹¤ ë´¤ë„¤   \n",
      "1  ì •ë§ ìƒìƒì„ ì´ˆì›”í•˜ëŠ” ë¬´ê°œë… ì§„ìƒë“¤ ìƒëŒ€í•˜ë‹¤ ìš°ìš¸ì¦ ê³µí•­ì¥ì•  ê±¸ë¦¬ëŠ” ê³µë¬´ì› ë§ì•„ìš” ...   \n",
      "2  ìƒˆë¡œìš´ ì„¸ìƒê³¼ ì¡°ìš°í•œ ìì˜ ì–´ë¦°ì•„ì´ ê°™ì€ ë°˜ì‘ ì–´ì©Œë©´ íšŒë³µëœ ê²ƒì€ ëˆˆì´ ì•„ë‹Œ ìˆœìˆ˜í•¨...   \n",
      "3       ë¯¸ì—­ì€ ì›ìƒìƒë¬¼ê³„ ì‚°í˜¸ì´ˆëŠ” ë™ë¬¼ã…‡ã…‡ ì•„ ë¯¸ì—­ì´ ë°”ë‹¤ì˜ ìƒˆã„±ã…‡ã„±ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹   \n",
      "4                        ë„¤ ë§ìŠµë‹ˆë‹¤ í”ŒìŠ¤ëŠ” ì—­ì‹œ 30í”„ë ˆì„ì´ ì–´ìš¸ë¦¬ì£  ã…   \n",
      "\n",
      "                                           tokenized  \n",
      "0  [ë‚´, ê°€, í†°í–‰í¬ìŠ¤, ë¥¼, ì¢‹ì•„í•˜, ê¸´, í–ˆ, ë‚˜, ë³´ë‹¤, ì´ˆê¸°, ì˜í™”, ë¹¼, ê³ ...  \n",
      "1  [ì •ë§, ìƒìƒ, ì„, ì´ˆì›”, í•˜, ëŠ”, ë¬´, ê°œë…, ì§„ìƒ, ë“¤, ìƒëŒ€, í•˜, ë‹¤, ...  \n",
      "2  [ìƒˆë¡œìš´, ì„¸ìƒ, ê³¼, ì¡°ìš°, í•œ, ì, ì˜, ì–´ë¦°ì•„ì´, ê°™, ì€, ë°˜ì‘, ì–´ì©Œë©´,...  \n",
      "3  [ë¯¸ì—­, ì€, ì›ìƒìƒë¬¼, ê³„, ì‚°í˜¸ì´ˆ, ëŠ”, ë™ë¬¼, ã…‡ã…‡, ì•„, ë¯¸ì—­, ì´, ë°”ë‹¤,...  \n",
      "4    [ë„¤, ë§, ìŠµë‹ˆë‹¤, í”Œ, ìŠ¤, ëŠ”, ì—­ì‹œ, 30, í”„ë ˆì„, ì´, ì–´ìš¸ë¦¬, ì£ , ã…]  \n"
     ]
    }
   ],
   "source": [
    "# âœ… CoreMLì—ëŠ” Mecab ë“± í˜•íƒœì†Œ ë¶„ì„ê¸°ë¥¼ í¬í•¨í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ\n",
    "# í•™ìŠµ ì‹œì—ë§Œ í˜•íƒœì†Œ ë‹¨ìœ„ í† í°í™”ë¥¼ ì§„í–‰í•˜ê³ ,\n",
    "# ë³€í™˜ ì‹œì—ëŠ” ìˆ«ì ì‹œí€€ìŠ¤ë¡œ ì €ì¥ëœ ê²°ê³¼ë§Œ ì‚¬ìš©í•´ì•¼ í•¨.\n",
    "\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "# ë¡œì»¬ í•™ìŠµìš© mecab ê²½ë¡œ ì„¤ì •\n",
    "mecab = Mecab(dicpath='/opt/homebrew/Cellar/mecab-ko-dic/2.1.1-20180720/lib/mecab/dic/mecab-ko-dic')\n",
    "\n",
    "def tokenize(text):\n",
    "    return mecab.morphs(text)\n",
    "\n",
    "train_df['tokenized'] = train_df['clean_text'].apply(tokenize)\n",
    "test_df['tokenized'] = test_df['clean_text'].apply(tokenize)\n",
    "val_df['tokenized'] = val_df['clean_text'].apply(tokenize)\n",
    "\n",
    "# âœ… ë³€í™˜ í›„ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì¶œë ¥ ì œê±°\n",
    "# print(train_df[['clean_text', 'tokenized']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c8e5e24-2f21-48b8-b7f9-c473ccbce250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          clean_text  \\\n",
      "0                  ë‚´ê°€ í†°í–‰í¬ìŠ¤ë¥¼ ì¢‹ì•„í•˜ê¸´ í–ˆë‚˜ë³´ë‹¤ ì´ˆê¸° ì˜í™” ë¹¼ê³ ëŠ” ë‹¤ ë´¤ë„¤   \n",
      "1  ì •ë§ ìƒìƒì„ ì´ˆì›”í•˜ëŠ” ë¬´ê°œë… ì§„ìƒë“¤ ìƒëŒ€í•˜ë‹¤ ìš°ìš¸ì¦ ê³µí•­ì¥ì•  ê±¸ë¦¬ëŠ” ê³µë¬´ì› ë§ì•„ìš” ...   \n",
      "2  ìƒˆë¡œìš´ ì„¸ìƒê³¼ ì¡°ìš°í•œ ìì˜ ì–´ë¦°ì•„ì´ ê°™ì€ ë°˜ì‘ ì–´ì©Œë©´ íšŒë³µëœ ê²ƒì€ ëˆˆì´ ì•„ë‹Œ ìˆœìˆ˜í•¨...   \n",
      "3       ë¯¸ì—­ì€ ì›ìƒìƒë¬¼ê³„ ì‚°í˜¸ì´ˆëŠ” ë™ë¬¼ã…‡ã…‡ ì•„ ë¯¸ì—­ì´ ë°”ë‹¤ì˜ ìƒˆã„±ã…‡ã„±ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹   \n",
      "4                        ë„¤ ë§ìŠµë‹ˆë‹¤ í”ŒìŠ¤ëŠ” ì—­ì‹œ 30í”„ë ˆì„ì´ ì–´ìš¸ë¦¬ì£  ã…   \n",
      "\n",
      "                                           tokenized  \n",
      "0  [ë‚´, í†°í–‰í¬ìŠ¤, ì¢‹ì•„í•˜, ê¸´, í–ˆ, ë‚˜, ë³´ë‹¤, ì´ˆê¸°, ì˜í™”, ë¹¼, ê³ , ë‹¤, ë´¤...  \n",
      "1  [ì •ë§, ìƒìƒ, ì„, ì´ˆì›”, í•˜, ë¬´, ê°œë…, ì§„ìƒ, ìƒëŒ€, í•˜, ë‹¤, ìš°ìš¸ì¦, ê³µ...  \n",
      "2  [ìƒˆë¡œìš´, ì„¸ìƒ, ì¡°ìš°, ì–´ë¦°ì•„ì´, ê°™, ë°˜ì‘, ì–´ì©Œë©´, íšŒë³µ, ëœ, ê²ƒ, ëˆˆ, ì•„...  \n",
      "3  [ë¯¸ì—­, ì›ìƒìƒë¬¼, ê³„, ì‚°í˜¸ì´ˆ, ë™ë¬¼, ã…‡ã…‡, ì•„, ë¯¸ì—­, ë°”ë‹¤, ìƒˆ, ã„±, ã…‡ã„±...  \n",
      "4          [ë„¤, ë§, ìŠµë‹ˆë‹¤, í”Œ, ìŠ¤, ì—­ì‹œ, 30, í”„ë ˆì„, ì–´ìš¸ë¦¬, ì£ , ã…]  \n"
     ]
    }
   ],
   "source": [
    "# âœ… ë¶ˆìš©ì–´ ì œê±°ëŠ” CoreML í™˜ê²½ì—ì„œ ë¶ˆê°€ëŠ¥í•˜ë¯€ë¡œ ì‚¬ì „ ì²˜ë¦¬ í•„ìˆ˜\n",
    "stopwords = [\n",
    "    \"ì˜\", \"ê°€\", \"ì´\", \"ì€\", \"ë“¤\", \"ëŠ”\", \"ê±\", \"ê³¼\",\n",
    "    \"ë¥¼\", \"ìœ¼ë¡œ\", \"ì\", \"ì—\", \"ì™€\", \"í•œ\", \"í•˜ë‹¤\", \"ì—ì„œ\",\n",
    "    \"ìš”\", \"ë¬´ì—‡\", \"ì–´ë””\", \"í•˜ë©´\", \"ì´ë‹¤\"\n",
    "]\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    return [token for token in tokens if token not in stopwords]\n",
    "\n",
    "# CoreML ëª¨ë¸ ì…ë ¥ìš© ì‹œí€€ìŠ¤ ìƒì„±ì„ ìœ„í•´ ë¶ˆìš©ì–´ ì œê±° ì ìš©\n",
    "train_df['tokenized'] = train_df['tokenized'].apply(remove_stopwords)\n",
    "test_df['tokenized'] = test_df['tokenized'].apply(remove_stopwords)\n",
    "val_df['tokenized'] = val_df['tokenized'].apply(remove_stopwords)\n",
    "\n",
    "# âœ… ì¶œë ¥ì€ ë³€í™˜ í›„ í•„ìš” ì—†ìŒ\n",
    "# print(train_df[['clean_text', 'tokenized']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "39ed77d9-f1f2-4ae4-bfce-0096be37b4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "íŒ¨ë”© í›„ ë°ì´í„° í¬ê¸°: (40000, 188)\n",
      "âœ… í…ìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# âœ… ì „ì²˜ë¦¬ëœ í† í°ë“¤ì„ ê³µë°±ìœ¼ë¡œ ì—°ê²°\n",
    "train_texts = train_df['tokenized'].apply(lambda x: ' '.join(x)).tolist()\n",
    "test_texts = test_df['tokenized'].apply(lambda x: ' '.join(x)).tolist()\n",
    "val_texts = val_df['tokenized'].apply(lambda x: ' '.join(x)).tolist()\n",
    "\n",
    "# âœ… í† í¬ë‚˜ì´ì € ì •ì˜ ë° ì»¤ìŠ¤í…€ í† í° ì¶”ê°€\n",
    "tokenizer = Tokenizer(oov_token=\"<OOV>\", filters='')\n",
    "custom_tokens = [\n",
    "    \"ã…‹ã…‹ã…‹\", \"ã…ã…ã…\", \"ã… ã… \", \"ã…œã…œ\", \"ã…¡ã…¡\", \"í—\", \"í—‰\", \"ã„·ã„·\", \"ëŒ€ë°•\",\n",
    "    \"ã„¹ã…‡\", \"ã„´ã„´\", \"ã…‡ã…‡\", \"ã…‡ã…‹\", \"ã„±ã„±\", \"ã„±ã……\", \"ã…Šã…‹\", \"ã……ã„±\", \"ã…ã…‡\", \"ã…‚ã…‡\", \"ã…‡ã…ˆ\",\n",
    "    \"ë…¸ì¼\", \"ê¿€ì¼\", \"ê°‘ë¶„ì‹¸\", \"ì¼ë¯¼ì´\", \"í˜„ì›ƒ\", \"ë§Œë ™\", \"ì–´ê·¸ë¡œ\", \"ë¶ˆê¸ˆ\", \"ã„¹ã…ˆã„·\", \"ì©ë‹¤\", \"ì¡´ë§›\", \"ì†”ê¹Œ\", \"ê·¹í˜\",\n",
    "    \"ã……ã…‚\", \"ã…ˆã„¹\", \"ã…„\", \"ì¡´ë‚˜\"\n",
    "]\n",
    "tokenizer.fit_on_texts(train_texts + [\" \".join(custom_tokens)])\n",
    "\n",
    "# âœ… ë‹¨ì–´ ì§‘í•© í¬ê¸°\n",
    "MAX_VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
    "\n",
    "# âœ… ì‹œí€€ìŠ¤ë¡œ ë³€í™˜\n",
    "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
    "val_sequences = tokenizer.texts_to_sequences(val_texts)\n",
    "\n",
    "# âœ… ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´ ê²°ì • ë° íŒ¨ë”©\n",
    "MAX_SEQUENCE_LENGTH = max(len(seq) for seq in train_sequences)\n",
    "train_padded = pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "test_padded = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "val_padded = pad_sequences(val_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "\n",
    "# âœ… TensorFlow Dataset êµ¬ì„±\n",
    "BATCH_SIZE = 64\n",
    "train_text_ds = tf.data.Dataset.from_tensor_slices((train_padded, train_labels)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_text_ds = tf.data.Dataset.from_tensor_slices((test_padded, test_labels)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "val_text_ds = tf.data.Dataset.from_tensor_slices((val_padded, val_labels)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# âœ… CoreML ì…ë ¥ì— ì‚¬ìš©ë˜ê¸° ìœ„í•´ ì‹œí€€ìŠ¤ì™€ ë¼ë²¨ ì €ì¥\n",
    "np.save(\"train_texts.npy\", train_padded)\n",
    "np.save(\"test_texts.npy\", test_padded)\n",
    "np.save(\"val_texts.npy\", val_padded)\n",
    "\n",
    "np.save(\"train_labels.npy\", train_labels)\n",
    "np.save(\"test_labels.npy\", test_labels)\n",
    "np.save(\"val_labels.npy\", val_labels)\n",
    "\n",
    "# âœ… Tokenizer ì €ì¥ (CoreML ì…ë ¥ ì²˜ë¦¬ìš©)\n",
    "with open(\"tokenizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "\n",
    "# âœ… ì¶œë ¥ ì œê±° (CoreML ë³€í™˜ ëŒ€ìƒì—ëŠ” ì‚¬ìš©ë˜ì§€ ì•ŠìŒ)\n",
    "# print(\"íŒ¨ë”© í›„ ë°ì´í„° í¬ê¸°:\", train_padded.shape)\n",
    "# print(\"âœ… í…ìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "268e0159-b2d3-4f3b-b03e-78c268131aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í›ˆë ¨ ë°ì´í„° í¬ê¸°: (40000, 188) (40000,)\n",
      "ê²€ì¦ ë°ì´í„° í¬ê¸°: (5000, 188) (5000,)\n",
      "í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°: (5000, 188) (5000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# âœ… CoreML ì…ë ¥ìš©ìœ¼ë¡œ ìµœì¢… ë„˜íŒŒì´ ë°°ì—´ ì •ë¦¬\n",
    "X_train, y_train = np.array(train_padded), np.array(train_labels)\n",
    "X_val, y_val = np.array(val_padded), np.array(val_labels)\n",
    "X_test, y_test = np.array(test_padded), np.array(test_labels)\n",
    "\n",
    "# âœ… CoreML ì¶”ë¡  ì‹œ ì‚¬ìš©ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì¶œë ¥ì€ ì£¼ì„ ì²˜ë¦¬\n",
    "# print(\"í›ˆë ¨ ë°ì´í„° í¬ê¸°:\", X_train.shape, y_train.shape) \n",
    "# print(\"ê²€ì¦ ë°ì´í„° í¬ê¸°:\", X_val.shape, y_val.shape)\n",
    "# print(\"í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db1810f2-068f-42e7-a68a-858fe71246c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ í…ìŠ¤íŠ¸ ë°ì´í„° ê°œìˆ˜ - Train: 625, Validation: 79, Test: 79\n"
     ]
    }
   ],
   "source": [
    "# âœ… ë°ì´í„° ê°œìˆ˜ í™•ì¸\n",
    "text_train_count = sum(1 for _ in train_text_ds)\n",
    "text_val_count = sum(1 for _ in val_text_ds)\n",
    "text_test_count = sum(1 for _ in test_text_ds)\n",
    "\n",
    "print(f\"ğŸ“ í…ìŠ¤íŠ¸ ë°ì´í„° ê°œìˆ˜ - Train: {text_train_count}, Validation: {text_val_count}, Test: {text_test_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9862f06e-780c-4cd3-b9cb-45272959d737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì…ë ¥ ë°ì´í„° í˜•íƒœ: (64, 188)\n",
      "ë¼ë²¨ ë°ì´í„° í˜•íƒœ: (64,)\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_text_ds.take(1):\n",
    "    print(\"ì…ë ¥ ë°ì´í„° í˜•íƒœ:\", x.shape)\n",
    "    print(\"ë¼ë²¨ ë°ì´í„° í˜•íƒœ:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "742f073c-a902-4c32-9e3e-bd7d98e8c343",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer, Dense, Dropout\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "class AttentionLayer(Layer):\n",
    "    def __init__(self, dropout_rate=0.1, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = Dense(input_shape[-1], activation='tanh')\n",
    "        self.V = Dense(1)\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        # (batch, time, 1)\n",
    "        score = self.V(self.W(inputs))\n",
    "\n",
    "        # âœ… ë§ˆìŠ¤í‚¹ ì ìš© (íŒ¨ë”©ëœ ë¶€ë¶„ì„ attentionì—ì„œ ì œì™¸)\n",
    "        if mask is not None:\n",
    "            mask = tf.cast(mask, tf.float32)          # (batch, time)\n",
    "            mask = tf.expand_dims(mask, axis=-1)      # (batch, time, 1)\n",
    "            score -= (1.0 - mask) * 1e9                # ë§¤ìš° ì‘ì€ ê°’ìœ¼ë¡œ ì–µì œ\n",
    "\n",
    "        attention_weights = K.softmax(score, axis=1)  # (batch, time, 1)\n",
    "        attention_weights = self.dropout(attention_weights)  # âœ… ë“œë¡­ì•„ì›ƒ ì ìš©\n",
    "        context_vector = attention_weights * inputs\n",
    "        context_vector = K.sum(context_vector, axis=1)  # (batch, features)\n",
    "        return context_vector\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return None  # ì¶œë ¥ì—ëŠ” ë§ˆìŠ¤í¬ ì ìš©í•˜ì§€ ì•ŠìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee2914e3-3282-401f-9a89-d00caf97634c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/mambaforge/base/envs/tf_metal/lib/python3.10/site-packages/keras/src/layers/layer.py:939: UserWarning: Layer 'conv1d_1' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)        â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">12,642,000</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">57,664</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_1           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ attention_layer_1               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,049</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AttentionLayer</span>)                â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">455</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m, \u001b[38;5;34m300\u001b[0m)        â”‚    \u001b[38;5;34m12,642,000\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚        \u001b[38;5;34m57,664\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_1           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m, \u001b[38;5;34m256\u001b[0m)        â”‚       \u001b[38;5;34m197,632\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ attention_layer_1               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚        \u001b[38;5;34m66,049\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mAttentionLayer\u001b[0m)                â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚        \u001b[38;5;34m16,448\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              â”‚           \u001b[38;5;34m455\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,980,504</span> (49.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,980,504\u001b[0m (49.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,980,376</span> (49.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,980,376\u001b[0m (49.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Embedding, Conv1D, BatchNormalization, LSTM, Bidirectional, Dropout, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# í•˜ì´í¼íŒŒë¼ë¯¸í„° ê¸°ë³¸ ì„¤ì •\n",
    "MAX_VOCAB_SIZE = len(tokenizer.word_index) + 1   # ì–´íœ˜ ì‚¬ì „ í¬ê¸°\n",
    "EMBEDDING_DIM = 300       # ì¤„ì¸ ì„ë² ë”© ì°¨ì›\n",
    "MAX_SEQUENCE_LENGTH = 98 # ë¬¸ì¥ ìµœëŒ€ ê¸¸ì´\n",
    "\n",
    "# 1. ëª¨ë¸ ìƒì„± í•¨ìˆ˜ ì •ì˜ (ê°„ì†Œí™”ëœ CNN + Bi-LSTM êµ¬ì¡°)\n",
    "def create_model(num_filters=64, kernel_size=3, lstm_units=128, dropout_rate=0.3, learning_rate=0.00023853):\n",
    "    model = Sequential()\n",
    "    # ì…ë ¥ ëª¨ì–‘ ëª…ì‹œ\n",
    "    model.add(Input(shape=(MAX_SEQUENCE_LENGTH,)))\n",
    "    # ì„ë² ë”© ë ˆì´ì–´ (input_length ì œê±°)\n",
    "    model.add(Embedding(input_dim=MAX_VOCAB_SIZE, output_dim=EMBEDDING_DIM, mask_zero=True))\n",
    "    \n",
    "    # CNN ë ˆì´ì–´: í•„í„° ìˆ˜ë¥¼ 32ë¡œ ì¤„ì„\n",
    "    model.add(Conv1D(filters=num_filters, kernel_size=kernel_size, activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    # ë‹¨ì¼ Bidirectional LSTM ë ˆì´ì–´ ì‚¬ìš© (ì¶œë ¥ ì‹œí€€ìŠ¤ ëŒ€ì‹  ìµœì¢… ì¶œë ¥ë§Œ ì‚¬ìš©)\n",
    "    model.add(Bidirectional(LSTM(lstm_units, return_sequences=True)))\n",
    "\n",
    "    #ğŸ”‘Attention ë©”ì»¤ë‹ˆì¦˜ ì¶”ê°€\n",
    "    model.add(AttentionLayer())\n",
    "\n",
    "    # âœ… AttentionLayer ì œê±° ì‹œ ì²˜ë¦¬ í•„ìš”\n",
    "    #model.add(tf.keras.layers.GlobalAveragePooling1D())  # ğŸ”‘ ì‹œí€€ìŠ¤ ì œê±° (ì¤‘ìš”)\n",
    "    \n",
    "    # ë“œë¡­ì•„ì›ƒ ë° Dense ë ˆì´ì–´\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(7, activation='softmax'))  # 7ê°œì˜ ê°ì • í´ë˜ìŠ¤\n",
    "\n",
    "    # ì˜µí‹°ë§ˆì´ì € ì„¤ì • (Adam)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, clipnorm=1.0) # clipnorm ì¶”ê°€ (accuracy ê¸‰ë½ ë°©ì§€)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# ì˜ˆì‹œë¡œ ëª¨ë¸ ìƒì„± ë° ìš”ì•½ ì¶œë ¥\n",
    "model = create_model(num_filters=64, kernel_size=3, lstm_units=128, dropout_rate=0.3,\n",
    "                     learning_rate=0.00023853)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6e2b8c6b-7bc5-4e09-8db3-30f168d90663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” Training model 1/7 (seed=42)...\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/mambaforge/base/envs/tf_metal/lib/python3.10/site-packages/keras/src/layers/layer.py:939: UserWarning: Layer 'conv1d_43' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 116ms/step - accuracy: 0.3327 - loss: 1.6813 - val_accuracy: 0.5344 - val_loss: 1.3719 - learning_rate: 3.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 117ms/step - accuracy: 0.5193 - loss: 1.3368 - val_accuracy: 0.4970 - val_loss: 1.4150 - learning_rate: 3.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.6472 - loss: 0.9126\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 117ms/step - accuracy: 0.6472 - loss: 0.9125 - val_accuracy: 0.4934 - val_loss: 1.4967 - learning_rate: 3.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 118ms/step - accuracy: 0.7766 - loss: 0.5206 - val_accuracy: 0.5050 - val_loss: 1.6440 - learning_rate: 1.5000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.8529 - loss: 0.3341\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 117ms/step - accuracy: 0.8529 - loss: 0.3340 - val_accuracy: 0.5326 - val_loss: 1.8039 - learning_rate: 1.5000e-04\n",
      "\n",
      "ğŸ” Training model 2/7 (seed=43)...\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/mambaforge/base/envs/tf_metal/lib/python3.10/site-packages/keras/src/layers/layer.py:939: UserWarning: Layer 'conv1d_44' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 120ms/step - accuracy: 0.2557 - loss: 1.7194 - val_accuracy: 0.5222 - val_loss: 1.3410 - learning_rate: 3.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 119ms/step - accuracy: 0.4799 - loss: 1.3949 - val_accuracy: 0.5102 - val_loss: 1.3503 - learning_rate: 3.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6269 - loss: 0.9699\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 119ms/step - accuracy: 0.6269 - loss: 0.9698 - val_accuracy: 0.4896 - val_loss: 1.4756 - learning_rate: 3.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 119ms/step - accuracy: 0.7611 - loss: 0.5734 - val_accuracy: 0.5544 - val_loss: 1.5116 - learning_rate: 1.5000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.8406 - loss: 0.3626\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 120ms/step - accuracy: 0.8406 - loss: 0.3625 - val_accuracy: 0.5290 - val_loss: 1.7591 - learning_rate: 1.5000e-04\n",
      "\n",
      "ğŸ” Training model 3/7 (seed=44)...\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/mambaforge/base/envs/tf_metal/lib/python3.10/site-packages/keras/src/layers/layer.py:939: UserWarning: Layer 'conv1d_45' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 120ms/step - accuracy: 0.2739 - loss: 1.7044 - val_accuracy: 0.4492 - val_loss: 1.5268 - learning_rate: 3.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.4975 - loss: 1.3627 - val_accuracy: 0.4958 - val_loss: 1.3550 - learning_rate: 3.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 121ms/step - accuracy: 0.6308 - loss: 0.9528 - val_accuracy: 0.4680 - val_loss: 1.5184 - learning_rate: 3.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.7464 - loss: 0.5882\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 120ms/step - accuracy: 0.7465 - loss: 0.5881 - val_accuracy: 0.5278 - val_loss: 1.5509 - learning_rate: 3.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 118ms/step - accuracy: 0.8466 - loss: 0.3348 - val_accuracy: 0.5416 - val_loss: 1.7578 - learning_rate: 1.5000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.9060 - loss: 0.2053\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 118ms/step - accuracy: 0.9061 - loss: 0.2052 - val_accuracy: 0.5428 - val_loss: 2.0138 - learning_rate: 1.5000e-04\n",
      "\n",
      "ğŸ” Training model 4/7 (seed=45)...\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/mambaforge/base/envs/tf_metal/lib/python3.10/site-packages/keras/src/layers/layer.py:939: UserWarning: Layer 'conv1d_46' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 117ms/step - accuracy: 0.2254 - loss: 1.7042 - val_accuracy: 0.5094 - val_loss: 1.5321 - learning_rate: 3.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 116ms/step - accuracy: 0.5032 - loss: 1.3415 - val_accuracy: 0.5258 - val_loss: 1.3671 - learning_rate: 3.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 117ms/step - accuracy: 0.6350 - loss: 0.9655 - val_accuracy: 0.5408 - val_loss: 1.5149 - learning_rate: 3.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.7641 - loss: 0.5837\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 119ms/step - accuracy: 0.7642 - loss: 0.5836 - val_accuracy: 0.5466 - val_loss: 1.6704 - learning_rate: 3.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 121ms/step - accuracy: 0.8587 - loss: 0.3353 - val_accuracy: 0.5564 - val_loss: 1.7933 - learning_rate: 1.5000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.9062 - loss: 0.2115\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.9062 - loss: 0.2114 - val_accuracy: 0.5552 - val_loss: 2.0931 - learning_rate: 1.5000e-04\n",
      "\n",
      "ğŸ” Training model 5/7 (seed=46)...\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/mambaforge/base/envs/tf_metal/lib/python3.10/site-packages/keras/src/layers/layer.py:939: UserWarning: Layer 'conv1d_47' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 122ms/step - accuracy: 0.2097 - loss: 1.7430 - val_accuracy: 0.3728 - val_loss: 1.6051 - learning_rate: 3.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.4766 - loss: 1.4627 - val_accuracy: 0.4500 - val_loss: 1.4911 - learning_rate: 3.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 122ms/step - accuracy: 0.6123 - loss: 1.0789 - val_accuracy: 0.4798 - val_loss: 1.5109 - learning_rate: 3.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.7354 - loss: 0.7366\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - accuracy: 0.7354 - loss: 0.7364 - val_accuracy: 0.4942 - val_loss: 1.6606 - learning_rate: 3.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 129ms/step - accuracy: 0.8302 - loss: 0.4461 - val_accuracy: 0.5082 - val_loss: 1.7959 - learning_rate: 1.5000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.8922 - loss: 0.2791\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 138ms/step - accuracy: 0.8922 - loss: 0.2790 - val_accuracy: 0.5018 - val_loss: 2.0777 - learning_rate: 1.5000e-04\n",
      "\n",
      "ğŸ” Training model 6/7 (seed=47)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/mambaforge/base/envs/tf_metal/lib/python3.10/site-packages/keras/src/layers/layer.py:939: UserWarning: Layer 'conv1d_48' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 135ms/step - accuracy: 0.3002 - loss: 1.6740 - val_accuracy: 0.4284 - val_loss: 1.5862 - learning_rate: 3.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 135ms/step - accuracy: 0.5318 - loss: 1.3131 - val_accuracy: 0.5054 - val_loss: 1.4004 - learning_rate: 3.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 136ms/step - accuracy: 0.6767 - loss: 0.8660 - val_accuracy: 0.4982 - val_loss: 1.5086 - learning_rate: 3.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.7946 - loss: 0.4902\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 136ms/step - accuracy: 0.7946 - loss: 0.4901 - val_accuracy: 0.4898 - val_loss: 1.7512 - learning_rate: 3.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 137ms/step - accuracy: 0.8796 - loss: 0.2703 - val_accuracy: 0.5372 - val_loss: 1.8588 - learning_rate: 1.5000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.9282 - loss: 0.1607\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 136ms/step - accuracy: 0.9282 - loss: 0.1607 - val_accuracy: 0.5350 - val_loss: 2.1627 - learning_rate: 1.5000e-04\n",
      "\n",
      "ğŸ” Training model 7/7 (seed=48)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/mambaforge/base/envs/tf_metal/lib/python3.10/site-packages/keras/src/layers/layer.py:939: UserWarning: Layer 'conv1d_49' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 135ms/step - accuracy: 0.2586 - loss: 1.7056 - val_accuracy: 0.3044 - val_loss: 1.7824 - learning_rate: 3.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 135ms/step - accuracy: 0.5114 - loss: 1.3468 - val_accuracy: 0.4420 - val_loss: 1.5654 - learning_rate: 3.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 134ms/step - accuracy: 0.6406 - loss: 0.9119 - val_accuracy: 0.5102 - val_loss: 1.4751 - learning_rate: 3.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 136ms/step - accuracy: 0.7642 - loss: 0.5473 - val_accuracy: 0.5214 - val_loss: 1.6432 - learning_rate: 3.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.8586 - loss: 0.3250\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 137ms/step - accuracy: 0.8586 - loss: 0.3250 - val_accuracy: 0.4912 - val_loss: 2.1140 - learning_rate: 3.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 138ms/step - accuracy: 0.9170 - loss: 0.1788 - val_accuracy: 0.5288 - val_loss: 2.1083 - learning_rate: 1.5000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.9572 - loss: 0.0978\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 137ms/step - accuracy: 0.9572 - loss: 0.0978 - val_accuracy: 0.5350 - val_loss: 2.4609 - learning_rate: 1.5000e-04\n"
     ]
    }
   ],
   "source": [
    "# 2. ë¯¸ë¦¬ ì •í•´ì§„(best) í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • (Grid Search ì—†ì´ ì§ì ‘ ì§€ì •)\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "# ê°€ì¤‘ì¹˜ ì œí•œ (ë„ˆë¬´ í° ê°€ì¤‘ì¹˜ ë°©ì§€)\n",
    "max_weight_limit = 7   # 10ì—ì„œ ë³€ê²½ \n",
    "adjusted_weights = np.clip(class_weights, 0, max_weight_limit)\n",
    "\n",
    "class_weights_dict = dict(enumerate(adjusted_weights))\n",
    "\n",
    "best_params = {\n",
    "    'num_filters': 64, # ë†’ì„ìˆ˜ë¡ ê³¼ì í•© 32ì—ì„œ ë³€ê²½\n",
    "    'kernel_size': 3, # ê³ ì •\n",
    "    'lstm_units': 128,  # ë†’ì„ìˆ˜ë¡ ê³¼ì í•©\n",
    "    'dropout_rate': 0.3, \n",
    "    'learning_rate': 0.0003, \n",
    "    'epochs': 50, # ê³ ì •\n",
    "    'batch_size': 64 # ë†’ì„ìˆ˜ë¡ ê³¼ì í•© 64ì—ì„œ ë³€ê²½\n",
    "}\n",
    "\n",
    "# 3. ì•™ìƒë¸” í•™ìŠµ: ë™ì¼í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ ì—¬ëŸ¬ ëª¨ë¸ì„ ê°œë³„ í•™ìŠµì‹œí‚´\n",
    "ensemble_models = []\n",
    "histories = []\n",
    "n_ensemble = 7  # ì‚¬ìš©í•  ëª¨ë¸ ê°œìˆ˜ 5ì—ì„œ ë³€ê²½\n",
    "\n",
    "# ğŸ”‘ EarlyStopping ë° ReduceLROnPlateau ì„¤ì • ì¶”ê°€\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)\n",
    "\n",
    "for i in range(n_ensemble):\n",
    "    print(f\"\\nğŸ” Training model {i+1}/{n_ensemble} (seed={42 + i})...\")\n",
    "\n",
    "    # âœ… seed ê³ ì • (ê°€ì¤‘ì¹˜ + ì…”í”Œ + NumPy ì¼ê´€ì„±)\n",
    "    tf.keras.utils.set_random_seed(42 + i)\n",
    "    \n",
    "    model = create_model(num_filters=best_params['num_filters'],\n",
    "                         kernel_size=best_params['kernel_size'],\n",
    "                         lstm_units=best_params['lstm_units'],\n",
    "                         dropout_rate=best_params['dropout_rate'],\n",
    "                         learning_rate=best_params['learning_rate'])\n",
    "    history = model.fit(X_train, y_train, \n",
    "                  epochs=best_params['epochs'], \n",
    "                  batch_size=best_params['batch_size'], \n",
    "                  validation_data = (X_val, y_val),\n",
    "                  callbacks=[early_stop, lr_scheduler],\n",
    "                  class_weight=class_weights_dict,\n",
    "                  verbose=1\n",
    "    )\n",
    "    ensemble_models.append(model)\n",
    "    histories.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cf88b959-c6d8-4875-8c97-66076d851caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ 1: ìµœê³  ê²€ì¦ ì •í™•ë„ = 0.5344\n",
      "ëª¨ë¸ 2: ìµœê³  ê²€ì¦ ì •í™•ë„ = 0.5544\n",
      "ëª¨ë¸ 3: ìµœê³  ê²€ì¦ ì •í™•ë„ = 0.5428\n",
      "ëª¨ë¸ 4: ìµœê³  ê²€ì¦ ì •í™•ë„ = 0.5564\n",
      "ëª¨ë¸ 5: ìµœê³  ê²€ì¦ ì •í™•ë„ = 0.5082\n",
      "ëª¨ë¸ 6: ìµœê³  ê²€ì¦ ì •í™•ë„ = 0.5372\n",
      "ëª¨ë¸ 7: ìµœê³  ê²€ì¦ ì •í™•ë„ = 0.5350\n",
      "\n",
      "ì„ íƒëœ ëª¨ë¸: ëª¨ë¸ 4 (ê²€ì¦ ì •í™•ë„: 0.5564)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Average\n",
    "\n",
    "# âœ… ì…ë ¥ ì •ì˜ (ê¸°ì¡´ê³¼ ë™ì¼í•œ ì‹œí€€ìŠ¤ ê¸¸ì´)\n",
    "ensemble_input = Input(shape=(MAX_SEQUENCE_LENGTH,), name=\"text_input\")\n",
    "\n",
    "# âœ… ëª¨ë“  ì•™ìƒë¸” ëª¨ë¸ë“¤ì˜ ì¶œë ¥ ê³„ì‚°\n",
    "model_outputs = [model(ensemble_input) for model in ensemble_models]\n",
    "\n",
    "# âœ… softmax í‰ê· \n",
    "avg_output = Average()(model_outputs)\n",
    "\n",
    "# âœ… ìµœì¢… ëª¨ë¸ ì •ì˜\n",
    "ensemble_model = Model(inputs=ensemble_input, outputs=avg_output)\n",
    "\n",
    "# âœ… .h5ë¡œ ì €ì¥ (CoreML ë³€í™˜ì„ ìœ„í•´ ì´ íŒŒì¼ì„ ì‚¬ìš©)\n",
    "ensemble_model.save(\"text_ensemble_model.h5\")\n",
    "print(\"âœ… ì•™ìƒë¸” í‰ê·  ëª¨ë¸ ì €ì¥ ì™„ë£Œ: text_ensemble_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_metal)",
   "language": "python",
   "name": "tf_metal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
